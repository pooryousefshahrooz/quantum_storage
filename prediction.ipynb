{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import read_csv\n",
    "# from pandas import datetime\n",
    "# from matplotlib import pyplot\n",
    "# # load dataset\n",
    "# def parser(x):\n",
    "# \treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "# series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# # summarize first few rows\n",
    "# print(series.head())\n",
    "# # line plot\n",
    "# series.plot()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import DataFrame\n",
    "# from pandas import concat\n",
    "# from pandas import read_csv\n",
    "# from pandas import datetime\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from math import sqrt\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# # date-time parsing function for loading the dataset\n",
    "# def parser(x):\n",
    "# \treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# # convert time series into supervised learning problem\n",
    "# def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "# \tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "# \tdf = DataFrame(data)\n",
    "# \tcols, names = list(), list()\n",
    "# \t# input sequence (t-n, ... t-1)\n",
    "# \tfor i in range(n_in, 0, -1):\n",
    "# \t\tcols.append(df.shift(i))\n",
    "# \t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "# \t# forecast sequence (t, t+1, ... t+n)\n",
    "# \tfor i in range(0, n_out):\n",
    "# \t\tcols.append(df.shift(-i))\n",
    "# \t\tif i == 0:\n",
    "# \t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "# \t\telse:\n",
    "# \t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "# \t# put it all together\n",
    "# \tagg = concat(cols, axis=1)\n",
    "# \tagg.columns = names\n",
    "# \t# drop rows with NaN values\n",
    "# \tif dropnan:\n",
    "# \t\tagg.dropna(inplace=True)\n",
    "# \treturn agg\n",
    "\n",
    "# # transform series into train and test sets for supervised learning\n",
    "# def prepare_data(series, n_test, n_lag, n_seq):\n",
    "# \t# extract raw values\n",
    "# \traw_values = series.values\n",
    "# \traw_values = raw_values.reshape(len(raw_values), 1)\n",
    "# \t# transform into supervised learning problem X, y\n",
    "# \tsupervised = series_to_supervised(raw_values, n_lag, n_seq)\n",
    "# \tsupervised_values = supervised.values\n",
    "# \t# split into train and test sets\n",
    "# \ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "# \treturn train, test\n",
    "\n",
    "# # make a persistence forecast\n",
    "# def persistence(last_ob, n_seq):\n",
    "# \treturn [last_ob for i in range(n_seq)]\n",
    "\n",
    "# # evaluate the persistence model\n",
    "# def make_forecasts(train, test, n_lag, n_seq):\n",
    "# \tforecasts = list()\n",
    "# \tfor i in range(len(test)):\n",
    "# \t\tX, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "# \t\t# make forecast\n",
    "# \t\tforecast = persistence(X[-1], n_seq)\n",
    "# \t\t# store the forecast\n",
    "# \t\tforecasts.append(forecast)\n",
    "# \treturn forecasts\n",
    "\n",
    "# # evaluate the RMSE for each forecast time step\n",
    "# def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "# \tfor i in range(n_seq):\n",
    "# \t\tactual = test[:,(n_lag+i)]\n",
    "# \t\tpredicted = [forecast[i] for forecast in forecasts]\n",
    "# \t\trmse = sqrt(mean_squared_error(actual, predicted))\n",
    "# \t\tprint('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "\n",
    "# # plot the forecasts in the context of the original dataset\n",
    "# def plot_forecasts(series, forecasts, n_test):\n",
    "# \t# plot the entire dataset in blue\n",
    "# \tpyplot.plot(series.values)\n",
    "# \t# plot the forecasts in red\n",
    "# \tfor i in range(len(forecasts)):\n",
    "# \t\toff_s = len(series) - n_test + i - 1\n",
    "# \t\toff_e = off_s + len(forecasts[i]) + 1\n",
    "# \t\txaxis = [x for x in range(off_s, off_e)]\n",
    "# \t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
    "# \t\tpyplot.plot(xaxis, yaxis, color='red')\n",
    "# \t# show the plot\n",
    "# \tpyplot.show()\n",
    "\n",
    "# # load dataset\n",
    "# series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# # configure\n",
    "# n_lag = 1\n",
    "# n_seq = 4\n",
    "# n_test = 10\n",
    "# # prepare data\n",
    "# train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "# for item in train:\n",
    "#     print(\"train\",item)\n",
    "# for item in test:\n",
    "#     print(\"test\",item)\n",
    "# # make forecasts\n",
    "# forecasts = make_forecasts(train, test, n_lag, n_seq)\n",
    "# print(\"forecasts \",forecasts)\n",
    "# # evaluate forecasts\n",
    "# evaluate_forecasts(test, forecasts, n_lag, n_seq)\n",
    "# # plot forecasts\n",
    "# plot_forecasts(series, forecasts, n_test+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmgen.models import uniform_tm,spike_tm,modulated_gravity_tm,random_gravity_tm,gravity_tm,exp_tm\n",
    "import csv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92291c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_demands(num_of_pairs):\n",
    "#     number_of_time_slots=12\n",
    "#     spike_mean=120\n",
    "#     num_spikes=2\n",
    "#     each_t_each_request_demand = {}\n",
    "#     tm = spike_tm(num_of_pairs+1,num_spikes,spike_mean,number_of_time_slots)\n",
    "#     for time in range(number_of_time_slots):\n",
    "#         traffic = tm.at_time(time)\n",
    "#         printed_pairs = []\n",
    "#         user_indx = -1\n",
    "#         for i in range(num_of_pairs):\n",
    "#             for j in range(num_of_pairs):\n",
    "#                 if i!=j:\n",
    "#                     if (i,j) not in printed_pairs and (j,i) not in printed_pairs:\n",
    "#                         printed_pairs.append((i,j))\n",
    "#                         printed_pairs.append((j,i))\n",
    "#                         user_indx+=1\n",
    "#                         demand = max(1,traffic[i][j])\n",
    "#                         try:\n",
    "#                             each_t_each_request_demand[time][user_indx] = demand\n",
    "#                         except:\n",
    "#                             each_t_each_request_demand[time] = {}\n",
    "#                             each_t_each_request_demand[time][user_indx] = demand\n",
    "#     #print(\"each_t_each_request_demand\",each_t_each_request_demand)\n",
    "#     return each_t_each_request_demand\n",
    "# each_user_pair_demands_file={0:\"user_pair_demands0.csv\",\n",
    "#                             1:\"user_pair_demands1.csv\",\n",
    "#                             2:\"user_pair_demands2.csv\"}\n",
    "# for i in range(3):\n",
    "#     with open(each_user_pair_demands_file[i], 'a') as newFile:                                \n",
    "#         newFileWriter = csv.writer(newFile)\n",
    "#         newFileWriter.writerow([\"Time\",\"Demand\"]) \n",
    "# for exp in range(1,10):\n",
    "#     each_t_each_request_demand = generate_demands(3)\n",
    "#     for i in range(3):\n",
    "#         for time in range(1,13):\n",
    "#             if time<10:\n",
    "#                 label = str(exp)+\"-0\"+str(time)\n",
    "#             else:\n",
    "#                 label = str(exp)+\"-\"+str(time)\n",
    "#             demand = each_t_each_request_demand[time-1][i]\n",
    "#             with open(each_user_pair_demands_file[i], 'a') as newFile:                                \n",
    "#                 newFileWriter = csv.writer(newFile)\n",
    "#                 newFileWriter.writerow([label,demand]) \n",
    "#     import pdb\n",
    "#     #pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc7e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bcd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "import csv\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "\t# extract raw values\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff_series = difference(raw_values, 1)\n",
    "\tdiff_values = diff_series.values\n",
    "\tdiff_values = diff_values.reshape(len(diff_values), 1)\n",
    "\t# rescale values to -1, 1\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaled_values = scaler.fit_transform(diff_values)\n",
    "\tscaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "\t# transform into supervised learning problem X, y\n",
    "\tsupervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "\tsupervised_values = supervised.values\n",
    "\t# split into train and test sets\n",
    "\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "\treturn scaler, train, test\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "\t# reshape training into [samples, timesteps, features]\n",
    "\tX, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\t# design network\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(y.shape[1]))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t# fit network\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make one forecast with an LSTM,\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "\t# reshape input pattern to [samples, timesteps, features]\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\t# make forecast\n",
    "\tforecast = model.predict(X, batch_size=n_batch)\n",
    "\t# convert to array\n",
    "\treturn [x for x in forecast[0, :]]\n",
    "\n",
    "# evaluate the persistence model\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "\tforecasts = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\tX, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "\t\t# make forecast\n",
    "\t\tforecast = forecast_lstm(model, X, n_batch)\n",
    "\t\t# store the forecast\n",
    "\t\tforecasts.append(forecast)\n",
    "\treturn forecasts\n",
    "\n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "\t# invert first forecast\n",
    "\tinverted = list()\n",
    "\tinverted.append(forecast[0] + last_ob)\n",
    "\t# propagate difference forecast using inverted first value\n",
    "\tfor i in range(1, len(forecast)):\n",
    "\t\tinverted.append(forecast[i] + inverted[i-1])\n",
    "\treturn inverted\n",
    "\n",
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "\tinverted = list()\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\t# create array from forecast\n",
    "\t\tforecast = array(forecasts[i])\n",
    "\t\tforecast = forecast.reshape(1, len(forecast))\n",
    "\t\t# invert scaling\n",
    "\t\tinv_scale = scaler.inverse_transform(forecast)\n",
    "\t\tinv_scale = inv_scale[0, :]\n",
    "\t\t# invert differencing\n",
    "\t\tindex = len(series) - n_test + i - 1\n",
    "\t\tlast_ob = series.values[index]\n",
    "\t\tinv_diff = inverse_difference(last_ob, inv_scale)\n",
    "\t\t# store\n",
    "\t\tinverted.append(inv_diff)\n",
    "\treturn inverted\n",
    "\n",
    "# evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "\tfor i in range(n_seq):\n",
    "\t\tactual = [row[i] for row in test]\n",
    "\t\tpredicted = [forecast[i] for forecast in forecasts]\n",
    "\t\trmse = sqrt(mean_squared_error(actual, predicted))\n",
    "\t\tprint('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "\n",
    "# plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "\t# plot the entire dataset in blue\n",
    "\tpyplot.plot(series.values)\n",
    "\t# plot the forecasts in red\n",
    "\tfor i in range(len(forecasts)):\n",
    "\t\toff_s = len(series) - n_test + i - 1\n",
    "\t\toff_e = off_s + len(forecasts[i]) + 1\n",
    "\t\txaxis = [x for x in range(off_s, off_e)]\n",
    "\t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
    "\t\tpyplot.plot(xaxis, yaxis, color='red')\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\n",
    "# load dataset\n",
    "# series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\n",
    "# configure\n",
    "\n",
    "# make forecasts\n",
    "def forcast_demands(prediction_window,t):\n",
    "    \n",
    "    series = read_csv('user_pair_demands0.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\n",
    "    n_lag = 1\n",
    "    n_seq = 3\n",
    "    n_test = 1\n",
    "    n_epochs = 1500\n",
    "    n_batch = 1\n",
    "    n_neurons = 1\n",
    "    # prepare data\n",
    "    scaler, train, test = prepare_data(series, n_test, t, prediction_window)\n",
    "    #print(train)\n",
    "    # fit model\n",
    "    model = fit_lstm(train, t, prediction_window, n_batch, n_epochs, n_neurons)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    forecasts = make_forecasts(model, n_batch, train, test, t, prediction_window)\n",
    "    print(\"actual forcases\",forecasts)\n",
    "    # inverse transform forecasts and test\n",
    "    forecasts = inverse_transform(series, forecasts, scaler, n_test+2)\n",
    "    #actual = [row[n_lag:] for row in test]\n",
    "    #actual = inverse_transform(series, actual, scaler, n_test+2)\n",
    "    # evaluate forecasts\n",
    "    #evaluate_forecasts(actual, forecasts, n_lag, prediction_window)\n",
    "    # plot forecasts\n",
    "    #plot_forecasts(series, forecasts, n_test+2)\n",
    "    return forecasts\n",
    "each_user_pair_predicted_demands_file = {0:\"each_user_pair_predicted_demands_file0.csv\",\n",
    "                                         1:\"each_user_pair_predicted_demands_file1.csv\",\n",
    "                                         2:\"each_user_pair_predicted_demands_file2.csv\"}\n",
    "for user_pair_indx in range(2,3):\n",
    "    for exp in range(100):\n",
    "        for prediction_window in [2,4,6,8,10,12]:\n",
    "            \n",
    "            for t in range(1,13):\n",
    "                #print(\"for time \",t)\n",
    "                forecasts = forcast_demands(prediction_window,t)\n",
    "                modified_forecasts = []\n",
    "                for predicted in forecasts:\n",
    "                    for value in predicted:\n",
    "                        modified_forecasts.append(max(1,value))\n",
    "                #print(\"forecasts\",forecasts)\n",
    "                with open(each_user_pair_predicted_demands_file[user_pair_indx], 'a') as newFile:                                \n",
    "                    newFileWriter = csv.writer(newFile)\n",
    "                    \n",
    "                    my_list = [\"Topology\",exp,user_pair_indx,t,prediction_window]\n",
    "                    for item in modified_forecasts:\n",
    "                        my_list.append(item)\n",
    "                    with open(each_user_pair_predicted_demands_file[user_pair_indx],'a') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow(my_list)\n",
    "    print(\"user_pair_indx %s for exp %s \"%(user_pair_indx,exp))\n",
    "print(\"done!\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76021998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc195e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
