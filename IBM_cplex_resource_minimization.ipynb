{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"implement our OR model. When we want to code an optimization model,\n",
    "we put a placeholder for that model (like a blank canvas), \n",
    "then add its elements (decision variables and constraints) to it.\"\"\"\n",
    "import csv\n",
    "from network import Network\n",
    "from workload import Work_load\n",
    "# from docplex.mp.progress import *\n",
    "# from docplex.mp.progress import SolutionRecorder\n",
    "import os\n",
    "import docplex.mp.model as cpx\n",
    "import pandas as pd\n",
    "from docplex.mp.progress import *\n",
    "from docplex.mp.progress import SolutionRecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPLEX_resource_cinsumption_minimization(network,work_load):\n",
    "    \n",
    "    \n",
    "    opt_model = cpx.Model(name=\"Storage problem model\")\n",
    "    #opt_model = Model(name=\"Storage problem model\")\n",
    "#     for t in work_load.T:\n",
    "#         for k in work_load.each_t_requests[t]:\n",
    "#             for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]:\n",
    "#     x_vars  = {(t,k,p): opt_model.integer_var(lb=0, ub= 100,\n",
    "#                               name=\"x_{0}_{1}_{2}\".format(t,k,p))  for t in work_load.T \n",
    "#                for k in work_load.each_t_requests[t] \n",
    "#                for p in network.each_request_virtual_paths[k]}\n",
    "    \n",
    "#     s_vars  = {(t,k,p): opt_model.integer_var(lb=0, ub= 100,\n",
    "#                               name=\"s_{0}_{1}_{2}\".format(t,k,p))  for t in work_load.T \n",
    "#                for k in work_load.each_t_requests[t] \n",
    "#                for p in network.each_request_real_paths[k]}\n",
    "    w_vars  = {(t,k,p): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                              name=\"w_{0}_{1}_{2}\".format(t,k,p))  for t in work_load.T \n",
    "               for k in work_load.each_t_requests[t] \n",
    "               for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]}\n",
    "    u_vars  = {(t,j,p): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                              name=\"u_{0}_{1}_{2}\".format(t,j,p))  for t in work_load.T \n",
    "               for j in network.storage_pairs for p in network.each_request_real_paths[j]}   \n",
    "\n",
    "\n",
    "    \n",
    "    #inventory evolution constraint\n",
    "    for t in work_load.T[1:]:\n",
    "        for j in network.storage_pairs:\n",
    "            for p_s in network.each_request_real_paths[j]:\n",
    "                opt_model.add_constraint(u_vars[t,j,p_s] == u_vars[t-1,j,p_s]-\n",
    "                opt_model.sum(w_vars[t-1,k,p] *network.get_required_purification_EPR_pairs(p,work_load.get_each_request_thrshold(k,t))\n",
    "                for k in work_load.each_t_requests[t] if k!=j for p in network.each_request_virtual_paths[k] \n",
    "                if network.check_path_include_sub_path(p_s,p))+\n",
    "                opt_model.sum(w_vars[t-1,j,p_s])\n",
    "                                     , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "    \n",
    "    # serving from inventory constraint\n",
    "    for t in work_load.T[1:]:\n",
    "        for j in network.storage_pairs:\n",
    "            for p_s in network.each_request_real_paths[j]:\n",
    "                opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]*network.get_required_purification_EPR_pairs(p,work_load.get_each_request_thrshold(k,t))\n",
    "                for k in work_load.each_t_requests[t] if k!=j for p in network.each_request_virtual_paths[k] \n",
    "                if network.check_path_include_sub_path(p_s,p))<=u_vars[t,j,p_s]\n",
    "                                     , ctname=\"inventory_serving_{0}_{1}_{2}\".format(t,j,p_s))  \n",
    "     \n",
    "    # Demand constriant\n",
    "    for t in work_load.T[1:]:\n",
    "        for k in  work_load.each_t_requests[t]:\n",
    "            opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "            for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]) >= \n",
    "                    work_load.each_t_each_request_demand[t][k], ctname=\"constraint_{0}_{1}\".format(t,k))\n",
    "    \n",
    "    #Edge constraint\n",
    "    for t in work_load.T:\n",
    "        for edge in network.set_E:\n",
    "            opt_model.add_constraint(\n",
    "                opt_model.sum(w_vars[t,k,p]*network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t)) for k in work_load.each_t_requests[t]\n",
    "                for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k] if network.check_path_include_edge(edge,p))\n",
    "                                     \n",
    "                 <= network.each_edge_capacity[edge], ctname=\"edge_capacity_{0}_{1}\".format(t,edge))\n",
    "     \n",
    "    # storage servers capacity constraint\n",
    "    for t in work_load.T:\n",
    "        for s1 in network.storage_nodes:\n",
    "            opt_model.add_constraint(opt_model.sum(u_vars[t,(s1,s2),p] \n",
    "                for s2 in network.storage_nodes if network.check_storage_pair_exist(s1,s2)\n",
    "                for p in network.each_request_real_paths[(s1,s2)])\n",
    "        <= network.get_storage_capacity(s1), ctname=\"storage_capacity_constraint_{0}_{1}\".format(t,s1))\n",
    "    \n",
    "    # constraints for serving from storage at time zero and 1 should be zero\n",
    "    for t in [0,1]:\n",
    "        opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                for k in work_load.each_t_requests[t] for p in network.each_request_virtual_paths[k] \n",
    "                )<=0, ctname=\"serving_from_inventory_{0}\".format(t))\n",
    "    \n",
    "    # constraints for putting in storage at time zero  should be zero\n",
    "    for t in [0]:\n",
    "        opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                for k in work_load.each_t_requests[t] for p in network.each_request_real_paths[k] \n",
    "                )<=0, ctname=\"storing_in_inventory_{0}\".format(t))   \n",
    "    \n",
    "    # constraint for inventory is zero at time zero \n",
    "    for t in [0]:\n",
    "        for j in network.storage_pairs:\n",
    "             for p_s in network.each_request_real_paths[j]:\n",
    "                    opt_model.add_constraint(u_vars[t,j,p_s] <=0, ctname=\"storage_capacity_constraint_{0}_{1}_{2}\".format(t,j,p_s))\n",
    "    \n",
    "    \"\"\"defining an objective, which is a linear expression\"\"\"\n",
    "    objective = opt_model.sum(1/len(work_load.T[1:])*1/len(work_load.each_t_real_requests[t])*1/work_load.each_t_each_request_demand[t][k]\n",
    "                              *(w_vars[t,k,p] * network.get_path_length(p)) for t in work_load.T[1:]\n",
    "                              for k in work_load.each_t_real_requests[t] \n",
    "                              for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]\n",
    "                              )\n",
    "    # for maximization\n",
    "    opt_model.minimize(objective)\n",
    "    \n",
    "#     opt_model.solve()\n",
    "    opt_model.print_information()\n",
    "    #try:\n",
    "    opt_model.solve()\n",
    "\n",
    "    #save_csv_file(w_vars,\"./optimization_solution_w_values.csv\")\n",
    "#         save_csv_file(x_vars,\"./optimization_solution_x_values.csv\")\n",
    "#         save_csv_file(s_vars,\"./optimization_solution_s_values.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#     opt_df = pd.DataFrame.from_dict(u_vars, orient=\"index\", \n",
    "#                                 columns = [\"variable_object\"])\n",
    "#     opt_df.index =  pd.MultiIndex.from_tuples(opt_df.index, \n",
    "#                                    names=[\"column_i\", \"column_j\"])\n",
    "#     opt_df.reset_index(inplace=True)\n",
    "\n",
    "#     opt_df[\"solution_value\"] =  opt_df[\"variable_object\"].apply(lambda item: item.solution_value)\n",
    "\n",
    "#     opt_df.drop(columns=[\"variable_object\"], inplace=True)\n",
    "#     opt_df.to_csv(\"./optimization_solution_u_values.csv\")\n",
    "\n",
    "    #print('docplex.mp.solution',opt_model.solution)\n",
    "    objective_value = 0\n",
    "    try:\n",
    "        objective_value =opt_model.solution.get_objective_value()\n",
    "    except:\n",
    "        pass\n",
    "    return objective_value\n",
    "#     except ValueError:\n",
    "#         print(ValueError)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading topology... abilene\n",
      "for number of storages round   4\n",
      "for path number  1\n",
      "Model: Storage problem model\n",
      " - number of variables: 330\n",
      "   - binary=0, integer=0, continuous=330\n",
      " - number of constraints: 528\n",
      "   - linear=528\n",
      " - parameters: defaults\n",
      " - objective: minimize\n",
      " - problem type is: LP\n",
      "the objective value for 4 storage nodes and 1 paths between each pair of nodes is 3.0\n",
      "for path number  2\n",
      "Warning: Duplicate variable name: w_0_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_0_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_0_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_0_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_0_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_0_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_0_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_1_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_1_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_1_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_1_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_1_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_1_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_2_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_2_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_2_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_2_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_2_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_2_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_3_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_3_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_3_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_3_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_3_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_3_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_4_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_4_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_4_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_4_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_4_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_4_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_5_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_5_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_5_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_5_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_5_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_5_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_6_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_6_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_6_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_6_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_6_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_6_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_7_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_7_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_7_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_7_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_7_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_7_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_8_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_8_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_8_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_8_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_8_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_8_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_9_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_9_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_9_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_9_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_9_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_9_(5, 7)_5',ub=365)\n",
      "Model: Storage problem model\n",
      " - number of variables: 600\n",
      "   - binary=0, integer=0, continuous=600\n",
      " - number of constraints: 582\n",
      "   - linear=582\n",
      " - parameters: defaults\n",
      " - objective: minimize\n",
      " - problem type is: LP\n",
      "the objective value for 4 storage nodes and 2 paths between each pair of nodes is 3.0\n",
      "for path number  3\n",
      "Warning: Duplicate variable name: w_0_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_0_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_0_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_0_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_0_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_0_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_0_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_0_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_0_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_0_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_0_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_0_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_0_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_1_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_1_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_1_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_1_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_1_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_1_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_1_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_1_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_1_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_1_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_1_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_1_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_2_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_2_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_2_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_2_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_2_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_2_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_2_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_2_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_2_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_2_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_2_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_2_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_3_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_3_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_3_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_3_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_3_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_3_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_3_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_3_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_3_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_3_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_3_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_3_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_4_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_4_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_4_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_4_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_4_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_4_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_4_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_4_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_4_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_4_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_4_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_4_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_5_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_5_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_5_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_5_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_5_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_5_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_5_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_5_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_5_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_5_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_5_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_5_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_6_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_6_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_6_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_6_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_6_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_6_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_6_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_6_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_6_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_6_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_6_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_6_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_7_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_7_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_7_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_7_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_7_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_7_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_7_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_7_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_7_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_7_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_7_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_7_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_8_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_8_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_8_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_8_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_8_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_8_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_8_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_8_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_8_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_8_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_8_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_8_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_9_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_9_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_9_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_9_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_9_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_9_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_9_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_9_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_9_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_9_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_9_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_9_(5, 7)_5',ub=365)\n",
      "Model: Storage problem model\n",
      " - number of variables: 880\n",
      "   - binary=0, integer=0, continuous=880\n",
      " - number of constraints: 636\n",
      "   - linear=636\n",
      " - parameters: defaults\n",
      " - objective: minimize\n",
      " - problem type is: LP\n",
      "the objective value for 4 storage nodes and 3 paths between each pair of nodes is 3.0\n",
      "for path number  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Duplicate variable name: w_0_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_0_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_0_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_0_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_0_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_0_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_0_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_0_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_0_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_0_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_0_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_0_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_0_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_0_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_0_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_0_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_0_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_0_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_0_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_0_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_1_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_1_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_1_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_1_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_1_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_1_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_1_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_1_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_1_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_1_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_1_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_1_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_1_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_1_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_1_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_1_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_1_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_1_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_1_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_2_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_2_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_2_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_2_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_2_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_2_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_2_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_2_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_2_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_2_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_2_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_2_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_2_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_2_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_2_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_2_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_2_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_2_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_2_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_3_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_3_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_3_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_3_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_3_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_3_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_3_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_3_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_3_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_3_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_3_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_3_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_3_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_3_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_3_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_3_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_3_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_3_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_3_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_4_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_4_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_4_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_4_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_4_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_4_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_4_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_4_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_4_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_4_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_4_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_4_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_4_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_4_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_4_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_4_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_4_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_4_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_4_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_5_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_5_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_5_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_5_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_5_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_5_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_5_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_5_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_5_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_5_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_5_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_5_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_5_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_5_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_5_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_5_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_5_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_5_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_5_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_6_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_6_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_6_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_6_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_6_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_6_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_6_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_6_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_6_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_6_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_6_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_6_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_6_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_6_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_6_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_6_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_6_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_6_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_6_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_7_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_7_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_7_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_7_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_7_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_7_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_7_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_7_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_7_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_7_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_7_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_7_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_7_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_7_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_7_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_7_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_7_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_7_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_7_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_8_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_8_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_8_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_8_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_8_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_8_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_8_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_8_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_8_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_8_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_8_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_8_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_8_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_8_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_8_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_8_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_8_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_8_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_8_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_9_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_9_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_9_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_9_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_9_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_9_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_9_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_9_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_9_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_9_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_9_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_9_(5, 7)_5',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(11, 0)_0 already used for docplex.mp.Var(type=C,name='w_9_(11, 0)_0',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 11)_1 already used for docplex.mp.Var(type=C,name='w_9_(7, 11)_1',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(7, 0)_2 already used for docplex.mp.Var(type=C,name='w_9_(7, 0)_2',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 11)_3 already used for docplex.mp.Var(type=C,name='w_9_(5, 11)_3',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 0)_4 already used for docplex.mp.Var(type=C,name='w_9_(5, 0)_4',ub=365)\n",
      "Warning: Duplicate variable name: w_9_(5, 7)_5 already used for docplex.mp.Var(type=C,name='w_9_(5, 7)_5',ub=365)\n",
      "Model: Storage problem model\n",
      " - number of variables: 1160\n",
      "   - binary=0, integer=0, continuous=1160\n",
      " - number of constraints: 690\n",
      "   - linear=690\n",
      " - parameters: defaults\n",
      " - objective: minimize\n",
      " - problem type is: LP\n"
     ]
    },
    {
     "ename": "DOcplexLimitsExceeded",
     "evalue": "**** Promotional version. Problem size limits exceeded, CPLEX code=1016",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCplexSolverError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/docplex/mp/cplex_engine.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, mdl, parameters, **kwargs)\u001b[0m\n\u001b[1;32m   1910\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m                 \u001b[0mcpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/cplex/__init__.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, paramsets)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_quadratic_nonzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlpopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/cplex/_internal/_procedural.py\u001b[0m in \u001b[0;36mlpopt\u001b[0;34m(env, lp)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPXXlpopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/cplex/_internal/_procedural.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, env, status, from_cb)\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0merror_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeterrorstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCplexSolverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCplexSolverError\u001b[0m: CPLEX Error  1016: Community Edition. Problem size limits exceeded. Purchase at http://ibm.biz/error1016.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDOcplexLimitsExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/23/q7nr2mkd60z1t1fs92cd0rd40000gp/T/ipykernel_10393/1735842780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;34m\"\"\"solve the optimization\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCPLEX_resource_cinsumption_minimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwork_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mobjective_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the objective value for %s storage nodes and %s paths between each pair of nodes is %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_storages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobjective_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/23/q7nr2mkd60z1t1fs92cd0rd40000gp/T/ipykernel_10393/1658439154.py\u001b[0m in \u001b[0;36mCPLEX_resource_cinsumption_minimization\u001b[0;34m(network, work_load)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mopt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mopt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m#save_csv_file(w_vars,\"./optimization_solution_w_values.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4341\u001b[0m                 \u001b[0;31m# take arg clean flag or this model's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4342\u001b[0m                 \u001b[0mused_clean_before_solve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_before_solve'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_before_solve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4343\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_clean_before_solve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex_timelimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex_mipgaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4344\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhave_credentials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4345\u001b[0m                 \u001b[0;31m# no context passed as argument, no Cplex installed, try model's own context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36m_solve_local\u001b[0;34m(self, context, clean_before_solve, lex_timelimits, lex_mipgaps)\u001b[0m\n\u001b[1;32m   4463\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDOcplexException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdocpx_e\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4465\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mdocpx_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4467\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36m_solve_local\u001b[0;34m(self, context, clean_before_solve, lex_timelimits, lex_mipgaps)\u001b[0m\n\u001b[1;32m   4454\u001b[0m                                              \u001b[0mclean_before_solve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_before_solve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4455\u001b[0m                                              \u001b[0mlex_timelimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlex_timelimits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4456\u001b[0;31m                                              lex_mipgaps=lex_mipgaps)\n\u001b[0m\u001b[1;32m   4457\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_solution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/docplex/mp/cplex_engine.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, mdl, parameters, **kwargs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m                 \u001b[0mcpx_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1016\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                 \u001b[0mcpx_status_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Promotional version. Problem size limits exceeded., CPLEX code=1016.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1943\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal_ce_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_multiobj_error_1300\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m1300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcpx_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/docplex/mp/model.py\u001b[0m in \u001b[0;36mfatal_ce_limits\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfatal_ce_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal_limits_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/docplex/mp/error_handler.py\u001b[0m in \u001b[0;36mfatal_limits_exceeded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfatal_limits_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mdocplex_error_stop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDOcplexLimitsExceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDOcplexLimitsExceeded\u001b[0m: **** Promotional version. Problem size limits exceeded, CPLEX code=1016"
     ]
    }
   ],
   "source": [
    "results_file_path = 'results_file_path.csv'\n",
    "network = Network('abilene')\n",
    "work_load = Work_load(network.user_pairs,\"time_demands_file.csv\")\n",
    "\n",
    "# print('network.set_E',network.set_E)\n",
    "# print('network.nodes',network.nodes)\n",
    "# print('network.user_pairs',network.user_pairs)\n",
    "# print('work_load.request_pairs',work_load.request_pairs)\n",
    "# print('work_load.each_t_requests',work_load.each_t_requests)\n",
    "# print('work_load.each_t_real_requests',work_load.each_t_real_requests)\n",
    "# print('work_load.each_t_each_request_demand',work_load.each_t_each_request_demand)\n",
    "# print('work_load.each_request_threshold',work_load.each_request_threshold)\n",
    "import pdb\n",
    "# pdb.set_trace()\n",
    "objective_values = []\n",
    "selected_storage_nodes = []\n",
    "selected_storage_pairs = []\n",
    "\n",
    "# nx.draw(network.g,with_labels=True)\n",
    "# plt.show()\n",
    "\n",
    "for number_of_storages in range(4,5):\n",
    "    network.reset_pair_paths()\n",
    "    network.get_each_user_pair_real_paths(network.user_pairs)\n",
    "    path_counter_id = 0\n",
    "    print(\"for number of storages round  \",number_of_storages)\n",
    "    \"\"\"select and add new storage pairs\"\"\"\n",
    "    network.get_new_storage_pairs(number_of_storages)\n",
    "    #print(\"network.storage_pairs\",network.storage_pairs)\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    network.get_each_user_pair_real_paths(network.storage_pairs)\n",
    "    \"\"\"we add a new virtual link to the graph\"\"\"\n",
    "#     for new_pair in new_storage_pairs:\n",
    "#         print(new_pair[0],new_pair[1])\n",
    "#         network.g.add_edge(new_pair[0],new_pair[1],weight=0)\n",
    "        \n",
    "    #print(\"this is our storage pairs \",network.storage_pairs)\n",
    "    each_user_pair_real_paths = {}\n",
    "    each_user_pair_virtual_paths = {}\n",
    "    \"\"\"with new storage pairs, we will check the solution for each number of paths(real and virtual)\"\"\"\n",
    "    for num_paths in range(1,5):\n",
    "        \n",
    "        \"\"\"first we add the real paths between storage pairs\"\"\"\n",
    "        \n",
    "        print(\"for path number \",num_paths)\n",
    "        for storage_pair in network.storage_pairs:\n",
    "            #print(\"going to get real paths between storage pair \",storage_pair)\n",
    "            paths = network.get_real_path(storage_pair,num_paths)\n",
    "            #print(\"got paths\",paths)\n",
    "            for path in paths:\n",
    "                network.set_each_path_length(path_counter_id,path)\n",
    "                network.set_of_paths[path_counter_id] = path\n",
    "                try:\n",
    "                    network.each_request_real_paths[storage_pair].append(path_counter_id)\n",
    "                except:\n",
    "                    network.each_request_real_paths[storage_pair]=[path_counter_id]\n",
    "                path_counter_id+=1\n",
    "                try:\n",
    "                    network.each_user_pair_real_paths[storage_pair].append(path)\n",
    "                except:\n",
    "                    network.each_user_pair_real_paths[storage_pair]=[path]\n",
    "#             print(\"for new storage pair we got real paths and it is\")\n",
    "#             print(network.each_user_pair_real_paths[storage_pair])\n",
    "        for user_pair in network.user_pairs:\n",
    "            paths = network.get_real_path(user_pair,num_paths)\n",
    "            for path in paths:\n",
    "                network.set_of_paths[path_counter_id] = path\n",
    "                network.set_each_path_length(path_counter_id,path)\n",
    "                try:\n",
    "                    network.each_request_real_paths[user_pair].append(path_counter_id)\n",
    "                except:\n",
    "                    network.each_request_real_paths[user_pair]=[path_counter_id]\n",
    "                path_counter_id+=1\n",
    "                try:\n",
    "                    network.each_user_pair_real_paths[user_pair].append(path)\n",
    "                except:\n",
    "                    network.each_user_pair_real_paths[user_pair]=[path]\n",
    "#             print(\"for user pair  we got real paths and it is\",user_pair)\n",
    "#             print(network.each_user_pair_real_paths[user_pair])\n",
    "            for storage_pair in network.storage_pairs:\n",
    "                \"\"\"add one new path to the previous paths\"\"\"\n",
    "                \n",
    "                for real_sub_path in network.each_user_pair_real_paths[storage_pair]:\n",
    "                    #for edge in real_sub_path:\n",
    "                        #network.g.remove_edge(edge[0],edge[1])\n",
    "                    #network.g.add_edge(storage_pair[0],storage_pair[1],weight=0)\n",
    "                    #print(\"we are going to add a virtual path for user pair %s that includes %s\"%(user_pair,real_sub_path))\n",
    "                    paths = network.get_paths_to_connect_users_to_storage(user_pair,real_sub_path,num_paths)\n",
    "                    \n",
    "                    #print(paths)\n",
    "                    \n",
    "                    for path in paths:\n",
    "                        network.set_each_path_length(path_counter_id,path)\n",
    "                        \"\"\"we remove the sub path that is connecting two storage pairs \n",
    "                        from the path because we do not want to check the edge capacity for the edges of this subpath\"\"\"\n",
    "                        path = network.remove_storage_pair_real_path_from_path(real_sub_path,path)\n",
    "                        \n",
    "                        network.set_of_paths[path_counter_id] = path\n",
    "                        try:\n",
    "                            network.each_request_virtual_paths[user_pair].append(path_counter_id)\n",
    "                        except:\n",
    "                            network.each_request_virtual_paths[user_pair]=[path_counter_id]\n",
    "                        path_counter_id+=1\n",
    "                        \n",
    "                        try:\n",
    "                            network.each_user_pair_virtual_paths[user_pair].append(path)\n",
    "                        except:\n",
    "                            network.each_user_pair_virtual_paths[user_pair]=[path]\n",
    "                    for pair in network.storage_pairs:\n",
    "                        network.each_request_virtual_paths[pair]=[]\n",
    "                    #network.get_virtual_path(user_pair,storage_pair,real_sub_path)\n",
    "                    #print(\"for user pair %s to storage pair %s we got real paths and it is:\"%(user_pair,storage_pair))\n",
    "                    #print(network.each_user_pair_virtual_paths[user_pair])\n",
    "                \n",
    "        \"\"\"we set the basic fidelity of each path and the oracle for achiving the target threshold\"\"\"        \n",
    "        network.set_each_path_basic_fidelity()\n",
    "        \n",
    "        \"\"\"we set the capacity of each storage node\"\"\"\n",
    "        \n",
    "        network.set_storage_capacity()\n",
    "        \n",
    "        \"\"\"we add new storage pairs as our user pairs and set the demand for them zero\"\"\"\n",
    "        \n",
    "        work_load.set_storage_pairs_as_user_pairs(network.storage_pairs)\n",
    "        \n",
    "        \"\"\"we set the fidelity threshold of each new storage pair as a user request\"\"\"\n",
    "        \n",
    "        work_load.set_threshold_fidelity_for_request_pairs(network.user_pairs,network.storage_pairs)\n",
    "        \n",
    "        \"\"\"we set the required EPR pairs to achieve each request threshold fidelity\"\"\"\n",
    "        network.set_required_EPR_pairs_for_path_fidelity_threshold()\n",
    "        \n",
    "        \n",
    "        \"\"\"we set at least one demand for each time to avoid divided by zero error\"\"\"\n",
    "        \n",
    "        work_load.check_demands_per_each_time(network.user_pairs)\n",
    "        \"\"\"we print all variables to check the variables and values\"\"\"\n",
    "        \n",
    "#         print(\"we ahve these parameters for network\")\n",
    "\n",
    "#         print('network.set_E',network.set_E)\n",
    "#         print('network.each_edge_capacity',network.each_edge_capacity)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         print('network.each_path_basic_fidelity',network.each_path_basic_fidelity)\n",
    "#         print('network.oracle_for_target_fidelity',network.oracle_for_target_fidelity)\n",
    "#         print('network.storage_pairs',network.storage_pairs)\n",
    "#         print('network.storage_nodes',network.storage_nodes)\n",
    "#         print('network.each_storage_capacity',network.each_storage_capacity)\n",
    "#         print('network.set_of_paths',network.set_of_paths)\n",
    "#         print('network.each_request_real_paths',network.each_request_real_paths)\n",
    "#         print('network.each_request_virtual_paths',network.each_request_virtual_paths)\n",
    "\n",
    "#         print(\"we now print workload parameters to check\")\n",
    "        \n",
    "#         print('work_load.T',work_load.T)\n",
    "#         print('work_load.num_requests',work_load.num_requests)\n",
    "#         print('work_load.request_pairs',work_load.request_pairs)\n",
    "#         print('work_load.each_t_requests',work_load.each_t_requests)\n",
    "#         print('work_load.each_t_real_requests',work_load.each_t_real_requests)\n",
    "#         print('work_load.time_intervals',work_load.time_intervals)\n",
    "#         print('work_load.each_t_each_request_demand',work_load.each_t_each_request_demand)\n",
    "#         print('work_load.each_request_threshold',work_load.each_request_threshold)\n",
    "#         print('work_load.each_user_request_fidelity_threshold',work_load.each_user_request_fidelity_threshold)\n",
    "        \n",
    "        import pdb\n",
    "        #pdb.set_trace()\n",
    "        \"\"\"solve the optimization\"\"\"        \n",
    "        try:\n",
    "            objective_value = CPLEX_resource_cinsumption_minimization(network,work_load)\n",
    "            objective_values.append(objective_value)\n",
    "            print(\"the objective value for %s storage nodes and %s paths between each pair of nodes is %s\"%(number_of_storages,num_paths,objective_value))\n",
    "            with open(results_file_path, 'a') as newFile:                                \n",
    "                newFileWriter = csv.writer(newFile)\n",
    "                newFileWriter.writerow([number_of_storages,num_paths,objective_value]) \n",
    "        except ValueError:\n",
    "            print(ValueError)\n",
    "            \n",
    "# work_load = Work_load()\n",
    "# network = Network('../data')\n",
    "\n",
    "# solution_value = CPLEX_resource_cinsumption_minimization(network,work_load)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(objective_values)\n",
    "print(network.max_edge_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Network(object):\n",
    "#     def __init__(self, config, data_dir='./data/'):\n",
    "#         #self.topology_file = data_dir + config.topology_file\n",
    "#         self.topology_file = 'data'\n",
    "#         self.set_E = [(1,2),(2,3),(3,4),(4,5),(2,7),(7,8),(8,9),(9,5),(5,6),(2,10),(10,11),(11,12),(12,5)]\n",
    "#         self.each_edge_capacity = {(1,2):20,(2,3):20,(3,4):20,(4,5):20,(2,7):20,(7,8):20,(8,9):20,\n",
    "#                                    (9,5):20,(5,6):20,(2,10):20,(10,11):20,(11,12):20,(12,5):20}\n",
    "        \n",
    "#         self.max_edge_capacity = 10\n",
    "#         self.set_of_paths = {0:[(1,2),(2,10),(10,11),(11,12),(12,5),(5,6)],\n",
    "#                              1:[(2,3),(3,4),(4,5)],\n",
    "#                             2:[(2,7),(7,8),(8,9),(9,5)],\n",
    "#                              3:[(10,11),(11,12)],\n",
    "#                             4:[(1,2),(2,5),(5,6)],5:[(1,2),(2,5),(5,6)],\n",
    "#                             6:[(2,10),(10,12),(12,5)],\n",
    "#                             7:[(1,2),(2,10),(10,12),(12,5),(5,6)]}\n",
    "#         self.each_path_basic_fidelity = {0:0.7,\n",
    "#                              1:0.8,\n",
    "#                             2:0.75,\n",
    "#                              3:0.9,\n",
    "#                             4:0.7,\n",
    "#                             5:0.6,\n",
    "#                             6:0.8,\n",
    "#                             7:0.8}\n",
    "#         self.oracle_for_target_fidelity={0:{0.7:2,0.8:3,0.9:2},\n",
    "#                              1:{0.7:2,0.8:3,0.9:2},\n",
    "#                             2:{0.7:3,0.8:4,0.9:2},\n",
    "#                              3:{0.7:3,0.8:4,0.9:2},\n",
    "#                             4:{0.7:3,0.8:4,0.9:2},\n",
    "#                             5:{0.7:3,0.8:4,0.9:2},\n",
    "#                             6:{0.7:3,0.8:4,0.9:2},\n",
    "#                             7:{0.7:2,0.8:4,0.9:2}} \n",
    "#         self.each_request_real_paths = {(1,6):[0],(2,5):[1,2],(10,12):[3]}\n",
    "#         self.each_request_virtual_paths = {(1,6):[3,4,7],(2,5):[6],(10,12):[]}\n",
    "#         self.storage_pairs = [(2,5),(10,12)]\n",
    "#         self.storage_nodes = [2,5,10,12]\n",
    "#         self.each_storage_capacity = {2:100,5:100,10:100,12:100}\n",
    "        \n",
    "#         #self.shortest_paths_file = self.topology_file +'_shortest_paths'\n",
    "#         #self.DG = nx.DiGraph()\n",
    "\n",
    "#         #self.load_topology()\n",
    "#         #self.calculate_paths()\n",
    "#     def get_required_purification_EPR_pairs(self,p,threshold):\n",
    "#         if threshold>=0.9:\n",
    "#             return self.oracle_for_target_fidelity[p][0.9]\n",
    "#         elif 0.8<threshold<0.9:\n",
    "#             return self.oracle_for_target_fidelity[p][0.8]\n",
    "#         elif threshold<0.8:\n",
    "#             return self.oracle_for_target_fidelity[p][0.7]\n",
    "#         else:\n",
    "#             return 1\n",
    "        \n",
    "#     def load_topology(self):\n",
    "#         print('[*] Loading topology...', self.topology_file)\n",
    "#         f = open(self.topology_file, 'r')\n",
    "#         header = f.readline()\n",
    "#         self.num_nodes = int(header[header.find(':')+2:header.find('\\t')])\n",
    "#         self.num_links = int(header[header.find(':', 10)+2:])\n",
    "#         f.readline()\n",
    "#         self.link_capacities = np.empty((self.num_links))\n",
    "#         self.link_weights = np.empty((self.num_links))\n",
    "#         for line in f:\n",
    "#             link = line.split('\\t')\n",
    "#             i, s, d, w, c = link\n",
    "#             print('this is our line',link,i, s, d, w, c)\n",
    "#             self.link_capacities[int(i)] = float(c)\n",
    "#             self.link_weights[int(i)] = int(w)\n",
    "#             self.DG.add_weighted_edges_from([(int(s),int(d),int(w))])\n",
    "#             self.set_E.append()\n",
    "        \n",
    "#         f.close()\n",
    "#         #print('nodes: %d, links: %d\\n'%(self.num_nodes, self.num_links))\n",
    "#         nx.draw_networkx(self.DG)\n",
    "#         plt.show()\n",
    "#     def check_path_include_sub_path(self,sub_path,path):\n",
    "#         if self.set_of_paths[sub_path] in self.set_of_paths[path]:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     def get_edges(self):\n",
    "#         return self.set_E\n",
    "#     def get_storage_capacity(self,storage):\n",
    "#         return self.each_storage_capacity[storage]\n",
    "#     def check_path_include_edge(self,edge,path):\n",
    "#         #print('edge is %s and path is %s and Paths is %s'%(edge,path,self.set_of_paths))\n",
    "#         if edge in self.set_of_paths[path]:\n",
    "#             return True\n",
    "#         elif edge not  in self.set_of_paths[path]:\n",
    "#             return False\n",
    "#     def check_storage_pair_exist(self,s1,s2):\n",
    "#         if (s1,s2) in self.storage_pairs:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     def check_request_use_path(self,k,p):\n",
    "#         if p in self.each_request_virtual_paths[k] or (p in self.each_request_virtual_paths[k]):\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     #         edge_capacity\n",
    "#     #         paths\n",
    "#     #         virtual_paths\n",
    "#     def get_path_length(self,path):\n",
    "#         return len(self.set_of_paths[path])\n",
    "#     def scale_network(self,each_edge_scaling):\n",
    "        \n",
    "#         for edge in self.set_E:\n",
    "#             self.each_edge_capacity[edge] = self.each_edge_capacity[edge]*each_edge_scaling\n",
    "            \n",
    "        \n",
    "# class Work_load(object):\n",
    "#     def __init__(self):\n",
    "#         self.T = [0,1,2]\n",
    "#         self.num_requests = 2\n",
    "#         self.request_pairs = [(1,6),(2,5),(10,12)]\n",
    "#         self.each_t_requests = {0:[(1,6),(2,5),(10,12)],1:[(1,6),(2,5),(10,12)],2:[(1,6),(2,5),(10,12)]}\n",
    "#         self.each_t_real_requests = {1:[(1,6)],2:[(1,6)]}\n",
    "#         self.time_intervals = 2\n",
    "#         self.each_t_each_request_demand = {0:{(1,6):10,(2,5):0,(10,12):0},\n",
    "#                                            1:{(1,6):1,(2,5):0,(10,12):0},2:{(1,6):10,(2,5):0,(10,12):0}}\n",
    "#         self.each_request_thrshold = {(1,6):{0:0.9,1:0.8,2:0.9},\n",
    "#                                      (2,5):{0:0.3,1:0.3,2:0.3},\n",
    "#                                      (10,12):{0:0.3,1:0.3,2:0.3}\n",
    "#                                      }\n",
    "#     def get_each_request_thrshold(self,k,t):\n",
    "#         return self.each_request_thrshold[k][t]\n",
    "#     def generate_workload_circle(self,alpha,T,request_pairs):\n",
    "#         new_t_request_demands = {}\n",
    "#         for t,request_demand in self.each_t_each_request_demand.items():\n",
    "#             new_t_request_demands[t] = {}\n",
    "#             for req,d in request_demand.items():\n",
    "#                 new_t_request_demands[t][req] = d*alpha\n",
    "#         for k,v in new_t_request_demands.items():\n",
    "#             self.each_t_each_request_demand[k] = v\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_csv_file(variable,file_name):\n",
    "    opt_df = pd.DataFrame.from_dict(variable, orient=\"index\", \n",
    "                                columns = [\"variable_object\"])\n",
    "    opt_df.index =  pd.MultiIndex.from_tuples(opt_df.index, \n",
    "                                   names=[\"column_i\", \"column_j\",\"column_k\"])\n",
    "    opt_df.reset_index(inplace=True)\n",
    "\n",
    "    opt_df[\"solution_value\"] =  opt_df[\"variable_object\"].apply(lambda item: item.solution_value)\n",
    "\n",
    "    opt_df.drop(columns=[\"variable_object\"], inplace=True)\n",
    "    opt_df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # connect a listener to the model\n",
    "# opt_model.add_progress_listener(TextProgressListener())\n",
    "# opt_model.solve(clean_before_solve=True);\n",
    "\n",
    "# for l, listener in enumerate(opt_model.iter_progress_listeners(), start=1):\n",
    "#     print(\"listener #{0} has type '{1}', clock={2}\".format(l, listener.__class__.__name__, listener.clock))\n",
    "# opt_model.clear_progress_listeners()\n",
    "# opt_model.add_progress_listener(TextProgressListener(clock='objective', absdiff=1, reldiff=0))\n",
    "# sol_recorder = SolutionRecorder()\n",
    "# opt_model.clear_progress_listeners()\n",
    "# opt_model.add_progress_listener(sol_recorder)\n",
    "# opt_model.solve(clean_before_solve=True);\n",
    "\n",
    "# # utility function to display recorded solutions in a recorder.\n",
    "# def display_recorded_solutions(rec):\n",
    "#     print('* The recorder contains {} solutions'.format(rec.number_of_solutions))\n",
    "#     for s, sol in enumerate(rec.iter_solutions(), start=1):\n",
    "#         sumvals = sum(v for _, v in sol.iter_var_values())\n",
    "#         print('  - solution #{0}, obj={1}, non-zero-values={2}, total={3}'.format(\n",
    "#            s, sol.objective_value, sol.number_of_var_values, sumvals))\n",
    "\n",
    "# display_recorded_solutions(sol_recorder)\n",
    "\n",
    "\n",
    "# sol_recorder2 = SolutionRecorder(clock='objective')\n",
    "# opt_model.clear_progress_listeners()\n",
    "# opt_model.add_progress_listener(sol_recorder2)\n",
    "# opt_model.solve(clean_before_solve=True)\n",
    "# display_recorded_solutions(sol_recorder2)\n",
    "# #large_hearts.add_progress_listener(TextProgressListener(clock='gap'))\n",
    "# # maximum non-improving time is 4 seconds.\n",
    "# opt_model.add_progress_listener(AutomaticAborter(max_no_improve_time=4))\n",
    "# # again use clean_before_solve to ensure deterministic run of this cell.\n",
    "# opt_model.solve(clean_before_solve=True, log_output=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"defining our decicion variables (that are integer)\n",
    "store decision variables in Python dictionaries (or Pandas Series)\n",
    "where dictionary keys are decision variables, and values are decision variable objects.\n",
    "A decision variable is defined with three main properties: \n",
    "its type (continuous, binary or integer), \n",
    "its lower bound (0 by default), and \n",
    "its upper bound (infinity by default)\"\"\"\n",
    "\n",
    "x_vars  = {(i,j): opt_model.integer_var(lb=l[i,j], ub= u[i,j],\n",
    "                              name=\"x_{0}_{1}\".format(i,j))  for i in set_I for j in set_J}\n",
    "\n",
    "# print(x_vars)#{(1, 1): docplex.mp.Var(type=I,name='x_1_1',lb(lower bound)=2,ub(upper bound)=10), \n",
    "##(1, 2): docplex.mp.Var(type=I,name='x_1_2',ub=10) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"set constraints. \n",
    "Any constraint has three parts: a left-hand side (normally a linear combination of decision variables),\n",
    "a right-hand side (usually a numeric value), and\n",
    "a sense (Less than or equal, Equal, or Greater than or equal).\n",
    "To set up any constraints, we need to set each part:\"\"\"\n",
    "\n",
    "# <= constraints\n",
    "constraints = {j : \n",
    "opt_model.add_constraint(\n",
    "    ct=opt_model.sum(a[i,j] * x_vars[i,j] for i in set_I) <= b[j], ctname=\"constraint_{0}\".format(j)) for j in set_J}\n",
    "# >= constraints\n",
    "constraints = {j : opt_model.add_constraint(ct=opt_model.sum(a[i,j] * x_vars[i,j] for i in set_I) >= b[j], ctname=\"constraint_{0}\".format(j)) for j in set_J}\n",
    "# == constraints\n",
    "constraints = {j : \n",
    "opt_model.add_constraint( ct=opt_model.sum(a[i,j] * x_vars[i,j] for i in set_I) == b[j], ctname=\"constraint_{0}\".format(j)) for j in set_J}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"we call the solver to solve our optimization model.\"\"\"\n",
    "# solving with local cplex\n",
    "opt_model.solve()\n",
    "\n",
    "# solving with cplex cloud\n",
    "# opt_model.solve(url=\"your_cplex_cloud_url\", key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"get results and post-process them\n",
    "If the problem is solved to optimality, we can get and process results as follows:\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "opt_df = pd.DataFrame.from_dict(x_vars, orient=\"index\", \n",
    "                                columns = [\"variable_object\"])\n",
    "opt_df.index =  pd.MultiIndex.from_tuples(opt_df.index, \n",
    "                               names=[\"column_i\", \"column_j\"])\n",
    "opt_df.reset_index(inplace=True)\n",
    "\n",
    "opt_df[\"solution_value\"] =  opt_df[\"variable_object\"].apply(lambda item: item.solution_value)\n",
    "    \n",
    "opt_df.drop(columns=[\"variable_object\"], inplace=True)\n",
    "opt_df.to_csv(\"./optimization_solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"input parameters\"\"\"\n",
    "# import random\n",
    "# n = 10\n",
    "# m = 5\n",
    "# set_I = range(1, n+1)\n",
    "# set_J = range(1, m+1)\n",
    "# # print(set_I)#range(1, 11)\n",
    "# # print(set_J)# range(1, 6)\n",
    "\n",
    "# c = {(i,j): random.normalvariate(0,1) for i in set_I for j in set_J}\n",
    "# a = {(i,j): random.normalvariate(0,5) for i in set_I for j in set_J}\n",
    "# l = {(i,j): random.randint(0,10) for i in set_I for j in set_J}\n",
    "# u = {(i,j): random.randint(10,20) for i in set_I for j in set_J}\n",
    "# b = {j: random.randint(0,30) for j in set_J}\n",
    "\n",
    "# print(c) {(1, 1): #-0.03927470599644141, (1, 2): 1.0333198122747003, (1, 3): ....\n",
    "\n",
    "\n",
    "from docplex.mp.progress import ProgressListener\n",
    "\n",
    "class AutomaticAborter(ProgressListener):\n",
    "    \"\"\" a simple implementation of an automatic search stopper.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_no_improve_time=10.):\n",
    "        super(AutomaticAborter, self).__init__(ProgressClock.All)\n",
    "        self.last_obj = None\n",
    "        self.last_obj_time = None\n",
    "        self.max_no_improve_time = max_no_improve_time\n",
    "        \n",
    "    def notify_start(self):\n",
    "        super(AutomaticAborter, self).notify_start()\n",
    "        self.last_obj = None\n",
    "        self.last_obj_time = None    \n",
    "        \n",
    "    def is_improving(self, new_obj, eps=1e-4):\n",
    "        last_obj = self.last_obj\n",
    "        return last_obj is None or (abs(new_obj- last_obj) >= eps)\n",
    "            \n",
    "    def notify_progress(self, pdata):\n",
    "        super(AutomaticAborter, self).notify_progress(pdata)\n",
    "        if pdata.has_incumbent and self.is_improving(pdata.current_objective):\n",
    "            self.last_obj = pdata.current_objective\n",
    "            self.last_obj_time = pdata.time\n",
    "            print('----> #new objective={0}, time={1}s'.format(self.last_obj, self.last_obj_time))\n",
    "        else:\n",
    "            # a non improving move\n",
    "            last_obj_time = self.last_obj_time\n",
    "            this_time = pdata.time\n",
    "            if last_obj_time is not None:\n",
    "                elapsed = (this_time - last_obj_time)\n",
    "                if elapsed >= self.max_no_improve_time:\n",
    "                    print('!! aborting cplex, elapsed={0} >= max_no_improve: {1}'.format(elapsed,\n",
    "                                                                             self.max_no_improve_time))\n",
    "                    self.abort()\n",
    "                else:\n",
    "                    print('----> non improving time={0}s'.format(elapsed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
