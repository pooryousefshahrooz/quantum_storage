{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "from network import Network\n",
    "#from workload import Work_load\n",
    "# from docplex.mp.progress import *\n",
    "# from docplex.mp.progress import SolutionRecorder\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from docplex.mp.progress import *\n",
    "from docplex.mp.progress import SolutionRecorder\n",
    "import networkx as nx\n",
    "import time\n",
    "from config import get_config\n",
    "from absl import flags\n",
    "FLAGS = flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPLEX_resource_cinsumption_minimization_edge_level(network,life_time,iteration,cyclic_workload,storage_capacity,delat_value):\n",
    "    #print(\"we are in edge level purificaiton \")\n",
    "    if cyclic_workload ==\"cyclic\":\n",
    "        cyclic_workload=True\n",
    "    else:\n",
    "        cyclic_workload= False\n",
    "    import docplex.mp.model as cpx\n",
    "    opt_model = cpx.Model(name=\"Storage problem model\"+str(iteration))\n",
    "    w_vars = {}\n",
    "    u_vars = {}\n",
    "#     print(\"we are going to print path info\")\n",
    "    \n",
    "    \n",
    "#     print(\"we are going to print path info\")\n",
    "#     print(\"each_t_real_request \",network.each_t_real_requests)\n",
    "#     print(\"each_t_all_request \",network.each_t_requests)\n",
    "#     print(\"storage pairs \",network.storage_pairs)\n",
    "#     for t in network.T:\n",
    "#         for k in network.each_t_requests[t]:\n",
    "#             for p in network.each_request_real_paths[k]:\n",
    "#                 print(\"request %s real path is %s\"%(k,p))\n",
    "#             print(\"real paths are done\")\n",
    "#             for p in network.each_request_virtual_paths[k]:\n",
    "#                 print(\"request %s virtual path %s \"%(k,p))\n",
    "#             print(\"virtual paths are done!\")\n",
    "#     print(\"we printed paths info\")\n",
    "    w_vars  = {(t,k,p): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                              name=\"w_{0}_{1}_{2}\".format(t,k,p))  for t in network.T \n",
    "               for k in network.each_t_requests[t] \n",
    "               for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]}\n",
    "\n",
    "    u_vars  = {(t,j,p): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                                  name=\"u_{0}_{1}_{2}\".format(t,j,p))  for t in network.T \n",
    "                   for j in network.storage_pairs for p in network.each_request_real_paths[j]}   \n",
    "\n",
    "    if life_time ==1000:\n",
    "        #inventory evolution constraint\n",
    "        for t in network.T[1:]:\n",
    "            for j in network.storage_pairs:\n",
    "                for p_s in network.each_request_real_paths[j]:\n",
    "                    \n",
    " \n",
    "                    if cyclic_workload:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == u_vars[(t-1)%len(network.T),j,p_s]-\n",
    "                        opt_model.sum(w_vars[(t-1)%len(network.T),k,p]\n",
    "                        \n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s])*delat_value\n",
    "                        +opt_model.sum(w_vars[(t-1)%len(network.T),j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "                    else:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == u_vars[t-1,j,p_s]-\n",
    "                        opt_model.sum(w_vars[t-1,k,p] \n",
    "                        \n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s])*delat_value\n",
    "                        +opt_model.sum(w_vars[t-1,j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "    else:\n",
    "        #inventory evolution constraint\n",
    "        for t in network.T[1:]:\n",
    "            for j in network.storage_pairs:\n",
    "                for p_s in network.each_request_real_paths[j]:\n",
    "                    \n",
    "                    if cyclic_workload:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == -\n",
    "                        opt_model.sum(w_vars[(t-1)%len(network.T),k,p] \n",
    "                        \n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                        )*delat_value\n",
    "                        + opt_model.sum(w_vars[(t-1)%len(network.T),j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "                    else:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == -\n",
    "                        opt_model.sum(w_vars[t-1,k,p] \n",
    "                        \n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                        )*delat_value\n",
    "                        + opt_model.sum(w_vars[t-1,j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "\n",
    "    # serving from inventory constraint\n",
    "    for t in network.T[1:]:\n",
    "        for j in network.storage_pairs:\n",
    "            \n",
    "            for p_s in network.each_request_real_paths[j]:\n",
    "\n",
    "                opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                \n",
    "                for k in network.each_t_requests[t] if k!=j \n",
    "                for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                if k in list(network.each_request_virtual_paths_include_subpath.keys()))*delat_value<=u_vars[t,j,p_s]\n",
    "                                     , ctname=\"inventory_serving_{0}_{1}_{2}\".format(t,j,p_s))  \n",
    " \n",
    "     \n",
    "    # Demand constriant\n",
    "    for t in network.T[1:]:\n",
    "        for k in  network.each_t_requests[t]:\n",
    "            opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "            for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]) >= \n",
    "                    network.each_t_each_request_demand[t][k], ctname=\"constraint_{0}_{1}\".format(t,k))\n",
    "    \n",
    "    #Edge constraint\n",
    "    for t in network.T:\n",
    "        for edge in network.set_E:\n",
    "            opt_model.add_constraint(\n",
    "                opt_model.sum(w_vars[t,k,p]*network.get_required_edge_level_purification_EPR_pairs(edge,p,network.each_t_requests[t],t) for k in network.each_t_requests[t]\n",
    "                for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k] if network.check_path_include_edge(edge,p))\n",
    "                                     \n",
    "                 <= network.each_edge_capacity[edge], ctname=\"edge_capacity_{0}_{1}\".format(t,edge))\n",
    "     \n",
    "    # storage servers capacity constraint\n",
    "#     storage_capacity = storage_capacity/delat_value\n",
    "    for t in network.T:\n",
    "        #for s1 in network.storage_nodes:\n",
    "        for j in network.storage_pairs:\n",
    "            opt_model.add_constraint(opt_model.sum(u_vars[t,j,p]\n",
    "                for p in network.each_request_real_paths[j]) <= storage_capacity \n",
    "        , ctname=\"storage_capacity_constraint_{0}_{1}\".format(t,j))\n",
    "            \n",
    "#     for t in work_load.T:\n",
    "#         for s1 in network.storage_nodes:\n",
    "#             opt_model.add_constraint(opt_model.sum(u_vars[t,(s1,s2),p] \n",
    "#                 for s2 in network.storage_nodes if network.check_storage_pair_exist(s1,s2)\n",
    "#                 for p in network.each_request_real_paths[(s1,s2)])\n",
    "#         <= storage_capacity, ctname=\"storage_capacity_constraint_{0}_{1}\".format(t,s1))\n",
    "    \n",
    "    # constraints for serving from storage at time zero and 1 should be zero\n",
    "    if not cyclic_workload:\n",
    "        for t in [0,1]:\n",
    "            opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                    for k in network.each_t_requests[t] for p in network.each_request_virtual_paths[k] \n",
    "                    )<=0, ctname=\"serving_from_inventory_{0}\".format(t))\n",
    "    \n",
    "    # constraints for putting in storage at time zero  should be zero\n",
    "    \"\"\"this is becasue we start the formulation from 1 and not from zero and we have t-1 in our formulation\"\"\"\n",
    "    for t in [0]:\n",
    "        opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                for k in network.each_t_requests[t] for p in network.each_request_real_paths[k] \n",
    "                )<=0, ctname=\"storing_in_inventory_{0}\".format(t))   \n",
    "    \n",
    "\n",
    "    # constraint for inventory is zero at time zero \n",
    "    if not cyclic_workload:\n",
    "        for t in [0]:\n",
    "            for j in network.storage_pairs:\n",
    "                 for p_s in network.each_request_real_paths[j]:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] <=0, ctname=\"storage_capacity_constraint_{0}_{1}_{2}\".format(t,j,p_s))\n",
    "    \n",
    "    \"\"\"defining an objective, which is a linear expression\"\"\"\n",
    "\n",
    "    objective = opt_model.sum(1/len(network.T[1:])*1/len(network.each_t_real_requests[t])*1/network.each_t_each_request_demand[t][k]\n",
    "                              *(w_vars[t,k,p] * network.get_path_length(p)) for t in network.T[1:]\n",
    "                              for k in network.each_t_real_requests[t] \n",
    "                              for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]\n",
    "                              )\n",
    "\n",
    "    \n",
    "  \n",
    "    opt_model.minimize(objective)\n",
    "    \n",
    "#     opt_model.print_information()\n",
    "    \n",
    "    opt_model.solve()\n",
    "\n",
    "    \n",
    "#     print('docplex.mp.solution',opt_model.solution)\n",
    "    objective_value = -1\n",
    "    try:\n",
    "        if opt_model.solution:\n",
    "            objective_value =opt_model.solution.get_objective_value()\n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "\n",
    "    each_inventory_per_time_usage = {}\n",
    "    each_time_each_path_delivered_EPRs = {}\n",
    "    each_time_each_path_purification_EPRs = {}\n",
    "    if objective_value>0:\n",
    "        \n",
    "#         for t in work_load.T[1:]:\n",
    "#             for k in work_load.each_t_real_requests[t]:\n",
    "#                 for p in network.each_request_virtual_paths[k]:\n",
    "#                     if network.get_path_length(p)==1:\n",
    "                        #print(\"this is the path length for path %s \"%(network.get_path_length(p)))\n",
    "                        #print(\"k is \",k)\n",
    "                        #print(network.storage_pairs)\n",
    "        \n",
    "        time.sleep(5)\n",
    "        for t in network.T[1:]:\n",
    "            for k in network.each_t_real_requests[t]: \n",
    "                for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]:\n",
    "                    try:\n",
    "                        each_time_each_path_delivered_EPRs[t][k]+=w_vars[t,k,p].solution_value\n",
    "                    except:\n",
    "                        try:\n",
    "                            each_time_each_path_delivered_EPRs[t][k]= w_vars[t,k,p].solution_value\n",
    "                        except:\n",
    "                            each_time_each_path_delivered_EPRs[t]={}\n",
    "                            each_time_each_path_delivered_EPRs[t][k]= w_vars[t,k,p].solution_value\n",
    "        \n",
    "                    try:\n",
    "                        each_time_each_path_purification_EPRs[t][k]+=network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                    except:\n",
    "                        try:\n",
    "                            each_time_each_path_purification_EPRs[t][k]= network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                        except:\n",
    "                            each_time_each_path_purification_EPRs[t]={}\n",
    "                            each_time_each_path_purification_EPRs[t][k]= network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))        \n",
    "        for t in network.T[1:]:\n",
    "            for j in network.storage_pairs:\n",
    "                for p in network.each_request_real_paths[j]:\n",
    "                    try:\n",
    "                        each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value\n",
    "                    except:\n",
    "                        try:\n",
    "                            each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value\n",
    "                        except:\n",
    "                            each_inventory_per_time_usage[j] = {}\n",
    "                            each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value        \n",
    "        \n",
    "    opt_model.clear()\n",
    "   \n",
    "    return objective_value,each_inventory_per_time_usage,each_time_each_path_delivered_EPRs,each_time_each_path_purification_EPRs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPLEX_resource_cinsumption_minimization(network,life_time,iteration,cyclic_workload,storage_capacity,delat_value):\n",
    "    #print(\"we are in end level purificaiton \")\n",
    "    if cyclic_workload ==\"cyclic\":\n",
    "        cyclic_workload=True\n",
    "    else:\n",
    "        cyclic_workload= False\n",
    "    import docplex.mp.model as cpx\n",
    "    opt_model = cpx.Model(name=\"Storage problem model\"+str(iteration))\n",
    "    w_vars = {}\n",
    "    u_vars = {}\n",
    "#     print(\"we are going to print path info\")\n",
    "#     print(\"each_t_real_request \",network.each_t_real_requests)\n",
    "#     print(\"each_t_all_request \",network.each_t_requests)\n",
    "#     print(\"storage pairs keys \",network.storage_pairs)\n",
    "#     print(\"network.pair_id\",network.pair_id)\n",
    "#     print(\"storage pairs \",network.storage_pairs)\n",
    "#     for t in network.T:\n",
    "#         for k in network.each_t_requests[t]:\n",
    "#             print(\"for k real \",k)\n",
    "#             for p in network.each_request_real_paths[k]:\n",
    "#                 print(\"request %s real path is %s\"%(k,p))\n",
    "#             print(\"for k virtual \",k)\n",
    "#             for p in network.each_request_virtual_paths[k]:\n",
    "#                 print(\"request %s virtual path %s \"%(k,p))\n",
    "#     print(\"we printed paths info\")\n",
    "    w_vars  = {(t,k,p): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                              name=\"w_{0}_{1}_{2}\".format(t,k,p))  for t in network.T \n",
    "               for k in network.each_t_requests[t] \n",
    "               for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]}\n",
    "\n",
    "    u_vars  = {(t,j,p): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                                  name=\"u_{0}_{1}_{2}\".format(t,j,p))  for t in network.T \n",
    "                   for j in network.storage_pairs for p in network.each_request_real_paths[j]}   \n",
    "\n",
    "    if life_time ==1000:\n",
    "        #inventory evolution constraint\n",
    "        for t in network.T[1:]:\n",
    "            for j in network.storage_pairs:\n",
    "                for p_s in network.each_request_real_paths[j]:\n",
    "                    \n",
    "                    #print(\"constraint evolution\")\n",
    "                    if cyclic_workload:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == u_vars[(t-1)%len(network.T),j,p_s]-\n",
    "                        opt_model.sum(w_vars[(t-1)%len(network.T),k,p] *\n",
    "                        network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s])*delat_value\n",
    "                        +opt_model.sum(w_vars[(t-1)%len(network.T),j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "                    else:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == u_vars[t-1,j,p_s]-\n",
    "                        opt_model.sum(w_vars[t-1,k,p] *\n",
    "                        network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s])*delat_value\n",
    "                        +opt_model.sum(w_vars[t-1,j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "    else:\n",
    "        #inventory evolution constraint\n",
    "        for t in network.T[1:]:\n",
    "            for j in network.storage_pairs:\n",
    "                for p_s in network.each_request_real_paths[j]:\n",
    "                    #print(\"constraint evolution2 \")\n",
    "                    if cyclic_workload:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == -\n",
    "                        opt_model.sum(w_vars[(t-1)%len(network.T),k,p] *\n",
    "                        network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                        )*delat_value\n",
    "                        + opt_model.sum(w_vars[(t-1)%len(network.T),j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "                    else:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] == -\n",
    "                        opt_model.sum(w_vars[t-1,k,p] *\n",
    "                        network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                        for k in network.each_t_requests[t] if k!=j \n",
    "                        for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                        )*delat_value\n",
    "                        + opt_model.sum(w_vars[t-1,j,p_s])*delat_value\n",
    "                                             , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "\n",
    "    # serving from inventory constraint\n",
    "    for t in network.T[1:]:\n",
    "        for j in network.storage_pairs:\n",
    "            #print(\"constraint inventory sevging\")\n",
    "            for p_s in network.each_request_real_paths[j]:\n",
    "                \n",
    "                opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]*\n",
    "                network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                for k in network.each_t_requests[t] if k!=j \n",
    "                for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                if k in list(network.each_request_virtual_paths_include_subpath.keys()))*delat_value<=u_vars[t,j,p_s]\n",
    "                                     , ctname=\"inventory_serving_{0}_{1}_{2}\".format(t,j,p_s))  \n",
    " \n",
    "     \n",
    "    # Demand constriant\n",
    "    for t in network.T[1:]:\n",
    "        for k in  network.each_t_requests[t]:\n",
    "            #print(\"constraint demand t %s k %s demand %s\"%(t,k,network.each_t_each_request_demand[t][k]))\n",
    "            opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "            for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]) >= \n",
    "                    network.each_t_each_request_demand[t][k], ctname=\"constraint_{0}_{1}\".format(t,k))\n",
    "    \n",
    "    #Edge constraint\n",
    "    for t in network.T:\n",
    "        for edge in network.set_E:\n",
    "            #print(\"edge constraint\")\n",
    "            opt_model.add_constraint(\n",
    "                opt_model.sum(w_vars[t,k,p]*network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t)) for k in network.each_t_requests[t]\n",
    "                for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k] if network.check_path_include_edge(edge,p))\n",
    "                                     \n",
    "                 <= network.each_edge_capacity[edge], ctname=\"edge_capacity_{0}_{1}\".format(t,edge))\n",
    "     \n",
    "    # storage servers capacity constraint\n",
    "#     storage_capacity = storage_capacity/delat_value\n",
    "    for t in network.T:\n",
    "        #for s1 in network.storage_nodes:\n",
    "        for j in network.storage_pairs:\n",
    "            #print(\"storage capacity constraint\")\n",
    "            opt_model.add_constraint(opt_model.sum(u_vars[t,j,p]\n",
    "                for p in network.each_request_real_paths[j]) <= storage_capacity \n",
    "        , ctname=\"storage_capacity_constraint_{0}_{1}\".format(t,j))\n",
    "            \n",
    "#     for t in work_load.T:\n",
    "#         for s1 in network.storage_nodes:\n",
    "#             opt_model.add_constraint(opt_model.sum(u_vars[t,(s1,s2),p] \n",
    "#                 for s2 in network.storage_nodes if network.check_storage_pair_exist(s1,s2)\n",
    "#                 for p in network.each_request_real_paths[(s1,s2)])\n",
    "#         <= storage_capacity, ctname=\"storage_capacity_constraint_{0}_{1}\".format(t,s1))\n",
    "    \n",
    "    # constraints for serving from storage at time zero and 1 should be zero\n",
    "    if not cyclic_workload:\n",
    "        for t in [0,1]:\n",
    "            #print(\"constraints for serving from storage at time zero\")\n",
    "            opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                    for k in network.each_t_requests[t] for p in network.each_request_virtual_paths[k] \n",
    "                    )<=0, ctname=\"serving_from_inventory_{0}\".format(t))\n",
    "    \n",
    "    # constraints for putting in storage at time zero  should be zero\n",
    "    \"\"\"this is becasue we start the formulation from 1 and not from zero and we have t-1 in our formulation\"\"\"\n",
    "    for t in [0]:\n",
    "        #print(\"constraints becasue we start the formulation from 1 and not\")\n",
    "        opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                for k in network.each_t_requests[t] for p in network.each_request_real_paths[k] \n",
    "                )<=0, ctname=\"storing_in_inventory_{0}\".format(t))   \n",
    "    \n",
    "\n",
    "    # constraint for inventory is zero at time zero \n",
    "    if not cyclic_workload:\n",
    "        for t in [0]:\n",
    "            #print(\"constraints constraint for inventory is zero at time zero \")\n",
    "            for j in network.storage_pairs:\n",
    "                 for p_s in network.each_request_real_paths[j]:\n",
    "                        opt_model.add_constraint(u_vars[t,j,p_s] <=0, ctname=\"storage_capacity_constraint_{0}_{1}_{2}\".format(t,j,p_s))\n",
    "    \n",
    "    \"\"\"defining an objective, which is a linear expression\"\"\"\n",
    "\n",
    "    objective = opt_model.sum(1/len(network.T[1:])*1/len(network.each_t_real_requests[t])*1/network.each_t_each_request_demand[t][k]\n",
    "                              *(w_vars[t,k,p] * network.get_path_length(p)) for t in network.T[1:]\n",
    "                              for k in network.each_t_real_requests[t] \n",
    "                              for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]\n",
    "                              )\n",
    "\n",
    "    \n",
    "  \n",
    "    opt_model.minimize(objective)\n",
    "    \n",
    "#     opt_model.print_information()\n",
    "    \n",
    "    opt_model.solve()\n",
    "\n",
    "    \n",
    "#     print('docplex.mp.solution',opt_model.solution)\n",
    "    objective_value = -1\n",
    "    try:\n",
    "        if opt_model.solution:\n",
    "            objective_value =opt_model.solution.get_objective_value()\n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "\n",
    "    each_inventory_per_time_usage = {}\n",
    "    each_time_each_path_delivered_EPRs = {}\n",
    "    each_time_each_path_purification_EPRs = {}\n",
    "    if objective_value>0:\n",
    "        \n",
    "#         for t in work_load.T[1:]:\n",
    "#             for k in work_load.each_t_real_requests[t]:\n",
    "#                 for p in network.each_request_virtual_paths[k]:\n",
    "#                     if network.get_path_length(p)==1:\n",
    "                        #print(\"this is the path length for path %s \"%(network.get_path_length(p)))\n",
    "                        #print(\"k is \",k)\n",
    "                        #print(network.storage_pairs)\n",
    "        \n",
    "        time.sleep(5)\n",
    "        for t in network.T[1:]:\n",
    "            for k in network.each_t_real_requests[t]: \n",
    "                for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]:\n",
    "                    try:\n",
    "                        each_time_each_path_delivered_EPRs[t][k]+=w_vars[t,k,p].solution_value\n",
    "                    except:\n",
    "                        try:\n",
    "                            each_time_each_path_delivered_EPRs[t][k]= w_vars[t,k,p].solution_value\n",
    "                        except:\n",
    "                            each_time_each_path_delivered_EPRs[t]={}\n",
    "                            each_time_each_path_delivered_EPRs[t][k]= w_vars[t,k,p].solution_value\n",
    "        \n",
    "                    try:\n",
    "                        each_time_each_path_purification_EPRs[t][k]+=network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                    except:\n",
    "                        try:\n",
    "                            each_time_each_path_purification_EPRs[t][k]= network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))\n",
    "                        except:\n",
    "                            each_time_each_path_purification_EPRs[t]={}\n",
    "                            each_time_each_path_purification_EPRs[t][k]= network.get_required_purification_EPR_pairs(p,network.get_each_request_threshold(k,t))        \n",
    "        for t in network.T[1:]:\n",
    "            for j in network.storage_pairs:\n",
    "                for p in network.each_request_real_paths[j]:\n",
    "                    try:\n",
    "                        each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value\n",
    "                    except:\n",
    "                        try:\n",
    "                            each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value\n",
    "                        except:\n",
    "                            each_inventory_per_time_usage[j] = {}\n",
    "                            each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value        \n",
    "        \n",
    "    opt_model.clear()\n",
    "   \n",
    "    return objective_value,each_inventory_per_time_usage,each_time_each_path_delivered_EPRs,each_time_each_path_purification_EPRs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feasibility(each_network_topology_file,results_file_path,inventory_utilization_results_file_path,delived_purification_EPRs_file_path,number_of_user_pairs,number_of_time_slots, spike_means,num_spikes,experiment_repeat,storage_node_selection_schemes,fidelity_threshold_ranges,cyclic_workload,storage_capacities,given_life_time_set,distance_between_users,setting_demands,edge_fidelity_ranges):\n",
    "    \n",
    "    config = get_config(FLAGS) or FLAGS\n",
    "    for edge_fidelity_range in edge_fidelity_ranges:\n",
    "        for network_topology,file_path in each_network_topology_file.items():\n",
    "            for spike_mean in each_topology_mean_value_spike[network_topology]:\n",
    "                import pdb\n",
    "                each_storage_each_path_number_value = {}\n",
    "                network = Network(config,file_path,False,edge_fidelity_range,max_edge_capacity_value,fidelity_threshold_ranges)\n",
    "\n",
    "                for i in range(experiment_repeat):\n",
    "                    network.reset_variables()\n",
    "                    network.get_user_pairs(number_of_user_pairs,distance_between_users,number_of_time_slots)\n",
    "                    #work_load = Work_load(number_of_time_slots,\"time_demands_file.csv\")\n",
    "                    \"\"\"we set the demands for each user pair\"\"\"\n",
    "                    if setting_demands==\"python_library\":\n",
    "                        network.set_each_user_pair_demands(number_of_time_slots,network.each_t_user_pairs,spike_mean,num_spikes)\n",
    "                    else:\n",
    "                        network.set_each_user_pair_demands_randomly(number_of_time_slots,network.each_t_user_pairs,spike_mean,num_spikes)\n",
    "                    \"\"\"we set at least one demand for each time to avoid divided by zero error\"\"\"\n",
    "                    network.check_demands_per_each_time(network.each_t_user_pairs)                                      \n",
    "                    for storage_capacity in storage_capacities:\n",
    "                        for fidelity_threshold_range in fidelity_threshold_ranges:\n",
    "                            network.fidelity_threshold_range = fidelity_threshold_range\n",
    "                            network.set_each_request_fidelity_threshold()\n",
    "#                             print(\"self.each_request_threshold \",network.each_request_threshold)\n",
    "                            for storage_node_selection_scheme in storage_node_selection_schemes:\n",
    "                                selected_storage_nodes = []\n",
    "                                selected_storage_pairs = []\n",
    "                                for num_paths in [1]:\n",
    "                                    network.reset_storage_pairs()\n",
    "                                    for number_of_storages in [0,2,4,8,10]:\n",
    "                                        try:\n",
    "                                            \"\"\"with new storage pairs, we will check the solution for each number of paths(real and virtual)\"\"\"\n",
    "                                            \n",
    "                                            pairs = []\n",
    "                                            \"\"\"select and add new storage pairs\"\"\"\n",
    "                                            available_flag = network.get_new_storage_pairs(number_of_storages,storage_node_selection_scheme)\n",
    "                                            network.set_each_storage_fidelity_threshold()\n",
    "                                            network.set_paths_in_the_network()\n",
    "                                            \n",
    "                                            for delat_value in delat_values:\n",
    "                                                for life_time in given_life_time_set:\n",
    "                                                    for purificaion_scheme in purification_schemes:\n",
    "                                                        \n",
    "                                                        objective_value=-1\n",
    "                                                        if network.path_existance_flag:\n",
    "#                                                             print(\"self.each_request_threshold \",network.each_request_threshold)\n",
    "                                                            #print(\"this is the number of storages \",number_of_storages)\n",
    "                                                            try:\n",
    "                                                                if purificaion_scheme ==\"end_level\":\n",
    "                                                                    objective_value,each_inventory_per_time_usage,each_time_each_path_delivered_EPRs,each_time_each_path_purification_EPRs = CPLEX_resource_cinsumption_minimization(network,life_time,i,cyclic_workload,storage_capacity,delat_value)\n",
    "                                                                else:\n",
    "                                                                    objective_value,each_inventory_per_time_usage,each_time_each_path_delivered_EPRs,each_time_each_path_purification_EPRs = CPLEX_resource_cinsumption_minimization_edge_level(network,life_time,i,cyclic_workload,storage_capacity,delat_value)\n",
    "                                                            except ValueError:\n",
    "                                                                print(ValueError)\n",
    "                                                        else:\n",
    "                                                            print(\"oops we do not have even one path for one k at a time!!\")\n",
    "                                                            objective_value = -1\n",
    "#                                                             for t in network.T:\n",
    "#                                                                 for k in network.each_t_requests[t]:\n",
    "#                                                                     for p in network.each_request_real_paths[k]:\n",
    "#                                                                         print(\"request %s real path is %s\"%(k,p))\n",
    "#                                                                     for p in network.each_request_virtual_paths[k]:\n",
    "#                                                                         print(\"request %s virtual path %s \"%(k,p))\n",
    "                                                        \n",
    "\n",
    "\n",
    "                                                        print(\"for purificaion %s topology %s iteration %s from %s spike mean %s capacity %s  fidelity range %s  life time %s storage %s and path number %s objective_value %s\"%\n",
    "                                                        (purificaion_scheme,network_topology,i,experiment_repeat, spike_mean,storage_capacity,fidelity_threshold_range,life_time, number_of_storages,num_paths, objective_value))  \n",
    "                                                        #print(\"storage nodes\",len(network.storage_nodes),len(network.storage_pairs))\n",
    "\n",
    "                                                        with open(results_file_path, 'a') as newFile:                                \n",
    "                                                            newFileWriter = csv.writer(newFile)\n",
    "                                                            newFileWriter.writerow([network_topology,number_of_storages,num_paths,\n",
    "                                                                                    life_time,\n",
    "                                                                                    objective_value,spike_mean,num_spikes,i,\n",
    "                                                                                    storage_node_selection_scheme,\n",
    "                                                                                    fidelity_threshold_range,cyclic_workload,\n",
    "                                                                                    distance_between_users,storage_capacity,edge_fidelity_range,delat_value,purificaion_scheme]) \n",
    "                                            \n",
    "                                        except:\n",
    "#                                             print(ValueError)\n",
    "                                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feasibility2(each_network_topology_file,results_file_path,inventory_utilization_results_file_path,delived_purification_EPRs_file_path,number_of_user_pairs,number_of_time_slots, spike_means,num_spikes,experiment_repeat,storage_node_selection_schemes,fidelity_threshold_ranges,cyclic_workload,storage_capacities,given_life_time_set,distance_between_users,setting_demands,edge_fidelity_ranges):\n",
    "    \n",
    "    print(\"each_network_topology_file %s \\n ,results_file_path %s , inventory_utilization_results_file_path %s ,number_of_user_pairs %s ,number_of_time_slots %s , spike_means %s ,num_spikes %s ,experiment_repeat %s ,storage_node_selection_schemes %s ,fidelity_threshold_ranges %s ,cyclic_workload %s ,storage_capacities %s ,given_life_time_set %s ,distance_between_users %s\"%(each_network_topology_file,results_file_path,inventory_utilization_results_file_path,number_of_user_pairs,number_of_time_slots, spike_means,num_spikes,experiment_repeat,storage_node_selection_schemes,fidelity_threshold_ranges,cyclic_workload,storage_capacities,given_life_time_set,distance_between_users))\n",
    "    for edge_fidelity_range in edge_fidelity_ranges:\n",
    "        for network_topology,file_path in each_network_topology_file.items():\n",
    "            for spike_mean in each_topology_mean_value_spike[network_topology]:\n",
    "                import pdb\n",
    "                each_storage_each_path_number_value = {}\n",
    "                network = Network(file_path,False,edge_fidelity_range,max_edge_capacity_value,fidelity_threshold_ranges)\n",
    "\n",
    "                for i in range(experiment_repeat):\n",
    "                    \n",
    "                    network.get_user_pairs(number_of_user_pairs,distance_between_users,number_of_time_slots)\n",
    "                    work_load = Work_load(number_of_time_slots,\"time_demands_file.csv\")\n",
    "                    \"\"\"we set the demands for each user pair\"\"\"\n",
    "                    if setting_demands==\"python_library\":\n",
    "                        work_load.set_each_user_pair_demands(number_of_time_slots,network.each_t_user_pairs,spike_mean,num_spikes)\n",
    "                    else:\n",
    "                        work_load.set_each_user_pair_demands_randomly(number_of_time_slots,network.each_t_user_pairs,spike_mean,num_spikes)\n",
    "                    \"\"\"we set at least one demand for each time to avoid divided by zero error\"\"\"\n",
    "                    work_load.check_demands_per_each_time(network.each_t_user_pairs)                                      \n",
    "                    for storage_capacity in storage_capacities:\n",
    "                        for fidelity_threshold_range in fidelity_threshold_ranges:\n",
    "                            network.set_user_pair_fidelity_threshold(fidelity_threshold_range)\n",
    "                            for storage_node_selection_scheme in storage_node_selection_schemes:\n",
    "\n",
    "                                objective_values = []\n",
    "                                selected_storage_nodes = []\n",
    "                                selected_storage_pairs = []\n",
    "\n",
    "                                #nx.draw(network.g,with_labels=True)\n",
    "                                # plt.show()\n",
    "                                for num_paths in [1]:\n",
    "                                    network.reset_storage_pairs()\n",
    "                                    for number_of_storages in [0,2,4,8,10]:\n",
    "                                        #if number_of_storages ==0:\n",
    "                                        #num_paths = 10-number_of_storages+1\n",
    "                                        try:\n",
    "                                            network.each_request_real_paths = {}\n",
    "                                            network.reset_pair_paths()\n",
    "                                            \"\"\"with new storage pairs, we will check the solution for each number of paths(real and virtual)\"\"\"\n",
    "                                            work_load.reset_variables()\n",
    "                                            pairs = []\n",
    "                                            for t,user_pairs in network.each_t_user_pairs.items():            \n",
    "                                                for user_pair in user_pairs:\n",
    "                                                    if user_pair not in pairs:\n",
    "                                                        pairs.append(user_pair)\n",
    "                                            network.get_each_user_pair_real_paths(pairs)\n",
    "\n",
    "                                            path_counter_id = 0\n",
    "                                            \"\"\"select and add new storage pairs\"\"\"\n",
    "                                            available_flag = network.get_new_storage_pairs(number_of_storages,storage_node_selection_scheme)\n",
    "                                            #if available_flag:\n",
    "                                            work_load.set_each_time_requests(network.each_t_user_pairs,network.storage_pairs)\n",
    "                                            work_load.set_each_time_real_requests(network.each_t_user_pairs)\n",
    "\n",
    "                                            network.get_each_user_pair_real_paths(network.storage_pairs)\n",
    "                                            if number_of_storages==1:\n",
    "                                                number_of_storages = 2\n",
    "\n",
    "                                            \"\"\"first we add the real paths between storage pairs\"\"\"\n",
    "                                            for storage_pair in network.storage_pairs:\n",
    "                                                paths = network.get_real_path(storage_pair,1,path_selection_scheme)\n",
    "                                                for path in paths:\n",
    "                                                    if network.get_this_path_fidelity(path)>=0.6:\n",
    "                                                        network.set_each_path_length(path_counter_id,path)\n",
    "                                                        network.set_of_paths[path_counter_id] = path\n",
    "                                                        network.each_path_path_id[tuple(path)] = path_counter_id\n",
    "                                                        try:\n",
    "                                                            network.each_request_real_paths[storage_pair].append(path_counter_id)\n",
    "                                                        except:\n",
    "                                                            network.each_request_real_paths[storage_pair]=[path_counter_id]\n",
    "                                                        try:\n",
    "                                                            network.each_storage_real_paths[storage_pair].append(path)\n",
    "                                                        except:\n",
    "                                                            network.each_storage_real_paths[storage_pair]=[path]\n",
    "                                                        path_counter_id+=1\n",
    "\n",
    "                                            across_all_time_slots_pairs = []\n",
    "                                            for t,user_pairs in network.each_t_user_pairs.items():\n",
    "                                                for user_pair in user_pairs:\n",
    "                                                    if user_pair not in across_all_time_slots_pairs:\n",
    "                                                        across_all_time_slots_pairs.append(user_pair)\n",
    "                                            all_sub_paths = []\n",
    "                                            for user_pair in across_all_time_slots_pairs:\n",
    "                                                paths = network.get_real_path(user_pair,num_paths,path_selection_scheme)\n",
    "                                                this_user_has_at_least_one_virtual_path_flag = False\n",
    "                                                for path in paths:\n",
    "                                                    if network.get_this_path_fidelity(path)>=0.6:\n",
    "                                                        network.set_of_paths[path_counter_id] = path\n",
    "                                                        network.set_each_path_length(path_counter_id,path)\n",
    "                                                        network.each_path_path_id[tuple(path)] = path_counter_id\n",
    "                                                        try:\n",
    "                                                            network.each_request_real_paths[user_pair].append(path_counter_id)\n",
    "                                                        except:\n",
    "                                                            network.each_request_real_paths[user_pair]=[path_counter_id]\n",
    "                                                        path_counter_id+=1\n",
    "\n",
    "                                                for storage_pair in network.storage_pairs:\n",
    "                                                    \"\"\"add one new path to the previous paths\"\"\"\n",
    "\n",
    "                                                    for real_sub_path in network.each_storage_real_paths[storage_pair]:\n",
    "                                                        this_sub_path_flag = False\n",
    "                                                        paths = network.get_paths_to_connect_users_to_storage(user_pair,real_sub_path,num_paths,path_selection_scheme)\n",
    "\n",
    "                                                        this_sub_path_id = network.each_path_path_id[tuple(real_sub_path)]\n",
    "                                                        if this_sub_path_id not in all_sub_paths:\n",
    "                                                            all_sub_paths.append(this_sub_path_id)\n",
    "                                                        for path in paths:\n",
    "                                                            if network.get_this_path_fidelity(path)>=0.6:\n",
    "                                                                this_sub_path_flag = True\n",
    "                                                                this_user_has_at_least_one_virtual_path_flag = True\n",
    "                                                                path = network.remove_storage_pair_real_path_from_path(real_sub_path,path)\n",
    "                                                                network.set_each_path_length(path_counter_id,path)\n",
    "                                                                \"\"\"we remove the sub path that is connecting two storage pairs \n",
    "                                                                from the path because we do not want to check the edge capacity for the edges of this subpath\"\"\"\n",
    "                                                                try:\n",
    "                                                                    network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id].append(path_counter_id)\n",
    "                                                                except:\n",
    "                                                                    try:\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[path_counter_id]\n",
    "                                                                    except:\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[user_pair]={}\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[path_counter_id]\n",
    "\n",
    "                                                                \n",
    "\n",
    "                                                                network.set_of_paths[path_counter_id] = path\n",
    "                                                                try:\n",
    "                                                                    network.each_request_virtual_paths[user_pair].append(path_counter_id)\n",
    "                                                                except:\n",
    "                                                                    network.each_request_virtual_paths[user_pair]=[path_counter_id]\n",
    "\n",
    "                                                                path_counter_id+=1\n",
    "\n",
    "\n",
    "                                                        for pair in network.storage_pairs:\n",
    "                                                            network.each_request_virtual_paths[pair]=[]\n",
    "                                                        if not this_sub_path_flag:\n",
    "                                                            try:\n",
    "                                                                network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[]\n",
    "                                                            except:\n",
    "                                                                network.each_request_virtual_paths_include_subpath[user_pair]={}\n",
    "                                                                network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[]\n",
    "\n",
    "                                                if not this_user_has_at_least_one_virtual_path_flag:\n",
    "                                                    network.each_request_virtual_paths[user_pair]=[]\n",
    "\n",
    "                                            if number_of_storages==0:\n",
    "                                                for t,pairs in network.each_t_user_pairs.items():\n",
    "                                                    for pair in pairs:\n",
    "                                                        network.each_request_virtual_paths[pair]=[]\n",
    "                                                        for j in network.storage_pairs:\n",
    "                                                            for sub_path_id in all_sub_paths:\n",
    "                                                                network.each_request_virtual_paths_include_subpath[pair][sub_path_id]={}\n",
    "                                            for j in network.storage_pairs:\n",
    "                                                for sub_path_id in all_sub_paths:\n",
    "                                                    try:\n",
    "                                                        network.each_request_virtual_paths_include_subpath[j][sub_path_id] = []\n",
    "                                                    except:\n",
    "                                                        network.each_request_virtual_paths_include_subpath[j]={}\n",
    "                                                        network.each_request_virtual_paths_include_subpath[j][sub_path_id] = []\n",
    "                                            for t in range(number_of_time_slots):\n",
    "                                                for k in work_load.each_t_requests[t]:\n",
    "                                                    for sub_path_id in all_sub_paths:\n",
    "                                                        try:\n",
    "                                                            if k in list(network.each_request_virtual_paths_include_subpath.keys()):\n",
    "                                                                if sub_path_id not in list(network.each_request_virtual_paths_include_subpath[k].keys()):\n",
    "\n",
    "                                                                    try:\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[k][sub_path_id] = []\n",
    "                                                                    except:\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[k]={}\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[k][sub_path_id] = []\n",
    "                                                                else:\n",
    "                                                                    action= \"do nothing!\"\n",
    "                                                            else:\n",
    "                                                                for sub_path_id in all_sub_paths:\n",
    "                                                                    try:\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[k][sub_path_id] = []\n",
    "                                                                    except:\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[k]={}\n",
    "                                                                        network.each_request_virtual_paths_include_subpath[k][sub_path_id] = []\n",
    "                                                        except:\n",
    "                                                            for sub_path_id in all_sub_paths:\n",
    "                                                                try:\n",
    "                                                                    network.each_request_virtual_paths_include_subpath[k][sub_path_id] = []\n",
    "                                                                except:\n",
    "                                                                    network.each_request_virtual_paths_include_subpath[k]={}\n",
    "                                                                    network.each_request_virtual_paths_include_subpath[k][sub_path_id] = []\n",
    "\n",
    "\n",
    "#                                             for t in work_load.T:\n",
    "#                                                 if number_of_storages!=0:\n",
    "#                                                     for j in network.storage_pairs:\n",
    "#                                                         for p_s in network.each_request_real_paths[j]:\n",
    "#         #                                                     print(\"for time %s and storage pair %s and real sub path %s\"%(t,j,p_s))\n",
    "#                                                             for k in work_load.each_t_requests[t]:\n",
    "#         #                                                         print(\"this is the request \",k)\n",
    "#                                                                 if k!=j:\n",
    "#         #                                                             print(\"which was not equal to storage pair\",t,j,p_s,k)\n",
    "#         #                                                             print(\"virtual including subpath\",network.each_request_virtual_paths_include_subpath[k])\n",
    "#         #                                                             print(\"network.each_request_virtual_paths[k]\",network.each_request_virtual_paths[k])\n",
    "#                                                                     for p in network.each_request_virtual_paths_include_subpath[k][p_s]:\n",
    "#                                                                         if p not in network.each_request_virtual_paths[k]:\n",
    "#                                                                             import pdb\n",
    "#                                                                             print(\"ERROR storages %s time %s request %s has a path %s for subpaths but it is not in his virtual paths %s\"%(number_of_storages,t,k,p,p_s))\n",
    "#                                                                             #print(network.each_request_real_paths[k])\n",
    "#                                                                             print(\"virtual paths including subpath list \",network.each_request_virtual_paths_include_subpath[k][p_s])\n",
    "#                                                                             print(\"virtual paths\",network.each_request_virtual_paths[k])\n",
    "#                                                                             pdb.set_trace()\n",
    "\n",
    "                                            import pdb\n",
    "\n",
    "\n",
    "                                            \"\"\"we set the capacity of each storage node\"\"\"\n",
    "\n",
    "                                            network.set_storage_capacity()\n",
    "\n",
    "                                            \"\"\"we add new storage pairs as our user pairs and set the demand for them zero\"\"\"\n",
    "\n",
    "                                            work_load.set_storage_pairs_as_user_pairs(network.storage_pairs)\n",
    "\n",
    "\n",
    "                                            \"\"\"we set the fidelity threshold of each new storage pair as a user request\"\"\"\n",
    "                                            network.set_each_path_basic_fidelity()\n",
    "                                            work_load.set_threshold_fidelity_for_request_pairs(network.each_t_user_pairs,network.storage_pairs,network.each_user_request_fidelity_threshold)\n",
    "\n",
    "                                            \"\"\"we set the required EPR pairs to achieve each request threshold fidelity\"\"\"\n",
    "                                            #network.set_required_EPR_pairs_for_path_fidelity_threshold()\n",
    "                                            flag_of_having_at_least_one_path = network.check_each_request_real_virtual_paths(work_load.T,work_load.each_t_requests)\n",
    "                                            network.set_required_EPR_pairs_for_each_path_each_fidelity_threshold()\n",
    "                                            if not flag_of_having_at_least_one_path:\n",
    "                                                for k in work_load.each_t_requests[t]:\n",
    "                                                    if k not in network.each_request_real_paths:\n",
    "                                                        print(\"we have not set real paths for this request\")\n",
    "                                                        paths = network.get_real_path(k,num_paths,path_selection_scheme)\n",
    "                                                        print(\"but these are paths \",paths)\n",
    "                                                        pdb.set_trace()\n",
    "                                                    if number_of_storages>0:\n",
    "                                                        if  k not in network.each_request_virtual_paths:\n",
    "                                                            print(\"we have not set virtual paths for this request\",k,number_of_storages,network.storage_pairs)\n",
    "                                                            available_flag = network.get_new_storage_pairs(number_of_storages,storage_node_selection_scheme)\n",
    "                                                            print(\"available_flag\",available_flag)\n",
    "                                                            for storage_pair in network.storage_pairs:\n",
    "                                                                print(\"for storage pair \",storage_pair)\n",
    "                                                                for real_sub_path in network.each_storage_real_paths[storage_pair]:\n",
    "                                                                    paths = network.get_paths_to_connect_users_to_storage(user_pair,real_sub_path,num_paths,path_selection_scheme)\n",
    "                                                                    print(\"we have these %s for this storage pair %s\"%(paths,storage_pair))\n",
    "                                                            pdb.set_trace()\n",
    "                                            \"\"\"solve the optimization\"\"\"\n",
    "                                            for delat_value in delat_values:\n",
    "                                                for life_time in given_life_time_set:\n",
    "                                                    for purificaion_scheme in purification_schemes:\n",
    "                                                        try:\n",
    "                                                            objective_value=-1\n",
    "                                                            if flag_of_having_at_least_one_path:\n",
    "                                                                try:\n",
    "                                                                    if purificaion_scheme ==\"end_level\":\n",
    "                                                                        objective_value,each_inventory_per_time_usage,each_time_each_path_delivered_EPRs,each_time_each_path_purification_EPRs = CPLEX_resource_cinsumption_minimization(network,work_load,life_time,i,cyclic_workload,storage_capacity,delat_value)\n",
    "                                                                    else:\n",
    "                                                                        objective_value,each_inventory_per_time_usage,each_time_each_path_delivered_EPRs,each_time_each_path_purification_EPRs = CPLEX_resource_cinsumption_minimization_edge_level(network,work_load,life_time,i,cyclic_workload,storage_capacity,delat_value)\n",
    "                                                                except ValueError:\n",
    "                                                                    print(ValueError)\n",
    "                                                            else:\n",
    "                                                                print(\"oops we do not have even one path for one k at a time!!\")\n",
    "                                                                objective_value = -1\n",
    "                                                            objective_values.append(objective_value)\n",
    "\n",
    "\n",
    "                                                            print(\"for topology %s iteration %s from %s spike mean %s capacity %s  fidelity range %s  life time %s storage %s and path number %s objective_value %s\"%\n",
    "                                                            (network_topology,i,experiment_repeat, spike_mean,storage_capacity,fidelity_threshold_range,life_time, number_of_storages,num_paths, objective_value))  \n",
    "\n",
    "\n",
    "                                                            with open(results_file_path, 'a') as newFile:                                \n",
    "                                                                newFileWriter = csv.writer(newFile)\n",
    "                                                                newFileWriter.writerow([network_topology,number_of_storages,num_paths,\n",
    "                                                                                        life_time,\n",
    "                                                                                        objective_value,spike_mean,num_spikes,i,\n",
    "                                                                                        storage_node_selection_scheme,\n",
    "                                                                                        fidelity_threshold_range,cyclic_workload,\n",
    "                                                                                        distance_between_users,storage_capacity,edge_fidelity_range,delat_value,purificaion_scheme]) \n",
    "                                                            for storage_pair,t_saved_EPRs in each_inventory_per_time_usage.items():\n",
    "                                                                for t ,EPRs in t_saved_EPRs.items():\n",
    "                                                                    this_slot_demands = work_load.get_each_t_whole_demands(t,network.each_t_user_pairs[t])\n",
    "                                                                    with open(inventory_utilization_results_file_path, 'a') as newFile:                                \n",
    "                                                                        newFileWriter = csv.writer(newFile)\n",
    "                                                                        newFileWriter.writerow([network_topology,number_of_storages,\n",
    "                                                                        num_paths,i,life_time,storage_pair,t,EPRs,spike_mean,\n",
    "                                                                        num_spikes,storage_node_selection_scheme,this_slot_demands,\n",
    "                                                                        fidelity_threshold_range,\n",
    "                                                                        cyclic_workload,distance_between_users,storage_capacity,edge_fidelity_range,delat_value])\n",
    "                                                            for t,k_delived_EPRs in  each_time_each_path_delivered_EPRs.items():\n",
    "                                                                this_slot_demands = work_load.get_each_t_whole_demands(t,network.each_t_user_pairs[t])\n",
    "                                                                for k,delived_EPRs in k_delived_EPRs.items():\n",
    "                                                                    purification_EPRs = each_time_each_path_purification_EPRs[t][k]\n",
    "                                                                    with open(delived_purification_EPRs_file_path, 'a') as newFile:                                \n",
    "                                                                        newFileWriter = csv.writer(newFile)\n",
    "                                                                        newFileWriter.writerow([network_topology,number_of_storages,\n",
    "                                                                        num_paths,i,t,life_time,spike_mean,\n",
    "                                                                        num_spikes,storage_node_selection_scheme,this_slot_demands,\n",
    "                                                                        fidelity_threshold_range,\n",
    "                                                                        cyclic_workload,distance_between_users,storage_capacity,\n",
    "                                                                        k,delived_EPRs,purification_EPRs,edge_fidelity_range,delat_value])\n",
    "\n",
    "                                                        except ValueError:\n",
    "                                                            #pass\n",
    "                                                            print(ValueError)\n",
    "                                        except ValueError:\n",
    "                                            print(ValueError)\n",
    "                                            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup with 400 max edge capacity and storage capacity 200 and 60 s time interval\n",
    "# works with mean in file results.. all_three_networks.csv\n",
    "\n",
    "experiment_repeat =100 #indicates the number of times that we repeat the experiment\n",
    "\n",
    "num_spikes = 3 # shows the number of nodes that have spike in their demand. Should be less than the number of user pairs\n",
    "topology_set = sys.argv[1] # can be either real, random1, or random2\n",
    "delat_values = [20]# each time interval is 1 minute or 60 seconds\n",
    "setting_demands = sys.argv[2] # indicates the way we generate the demands. python_library for using tgem library. ransom for generating a random demand\n",
    "number_of_user_pairs =int(sys.argv[3])\n",
    "spike_means = [1] # list of mean value for spike model traffic generation\n",
    "edge_fidelity_ranges = [(0.94,0.94)]\n",
    "max_edge_capacity_value = 1400\n",
    "path_selection_scheme = \"shortest\"\n",
    "purification_schemes = [\"end_level\",\"edge_level\"]\n",
    "each_topology_mean_value_spike = {}\n",
    "if setting_demands not in [\"random\",\"python_library\"]:\n",
    "    print(\"please run the script by python IBM_cplex_feasibiloty.py real/random1/random2 random/python_library\")\n",
    "else:\n",
    "    storage_node_selection_schemes=[\"Degree\",\"Random\"]\n",
    "    storage_node_selection_schemes=[\"Degree\"]\n",
    "    cyclic_workload = \"sequential\"\n",
    "    storage_capacities = [800,1200,1500,2000]\n",
    "    storage_capacities = [50,100,200,300,400,600,800,1000,1500,2000,4000,6000]\n",
    "    storage_capacities = [12000]\n",
    "    fidelity_threshold_ranges = [0.75,0.8,0.85,0.9,0.92,0.94,0.96,0.98]\n",
    "    fidelity_threshold_ranges = [0.9,0.94]\n",
    "    distance_between_users = 2\n",
    "\n",
    "    given_life_time_set = [1000]# 1000 indicates infinite time slot life time and 2 indicates one time slot life\n",
    "    \n",
    "    number_of_time_slots = 10\n",
    "    results_file_path = 'results/results_feasibility_final_20_sec_interval_edge_level_end_level.csv'\n",
    "    inventory_utilization_results_file_path = 'results/inventory_feasibility_utilization_final_20_sec_interval_new_formulation.csv'\n",
    "    delived_purification_EPRs_file_path = 'results/delived_purification_EPRs_file_path_final_20_sec_interval_new_formulation.csv'\n",
    "    each_network_topology_file = {}\n",
    "    if topology_set ==\"real\":\n",
    "        each_network_topology_file = {\"SURFnet\":'data/Surfnet',\"Abilene\":'data/abilene',\"IBM\":'data/IBM',\"ATT\":'data/ATT_topology_file'}\n",
    "        each_network_topology_file = {\"SURFnet\":'data/Surfnet',\"IBM\":'data/IBM',\"ATT\":'data/ATT_topology_file',\"Abilene\":'data/abilene'}\n",
    "        each_topology_mean_value_spike={\"ATT\":[350],\"IBM\":[350],\"SURFnet\":[350],\"Abilene\":[350]\n",
    "                               }\n",
    "    elif topology_set ==\"random1\":\n",
    "        for i in [2,4,6]:\n",
    "            each_network_topology_file[\"random_erdos_renyi2_\"+str(i)]= \"data/random_erdos_renyi2_\"+str(i)+\".txt\"\n",
    "            each_topology_mean_value_spike[\"random_erdos_renyi2_\"+str(i)] = [200]\n",
    "            each_network_topology_file[\"random_barabasi_albert2_\"+str(i)]= \"data/random_barabasi_albert2_\"+str(i)+\".txt\"\n",
    "            each_topology_mean_value_spike[\"random_barabasi_albert2_\"+str(i)] = [200]\n",
    "    # each_network_topology_file = {\"Testing_topology\":'data/test_topology'}\n",
    "        \n",
    "    elif topology_set ==\"random2\":\n",
    "        for i in range(1,4):\n",
    "            each_network_topology_file[\"random_erdos_renyi_\"+str(i)]= \"data/random_erdos_renyi_\"+str(i)+\".txt\"\n",
    "            each_network_topology_file[\"random_barabasi_albert_\"+str(i)]= \"data/random_barabasi_albert_\"+str(i)+\".txt\"\n",
    "        \n",
    "            each_topology_mean_value_spike[\"random_erdos_renyi_\"+str(i)] = [300]\n",
    "            each_topology_mean_value_spike[\"random_barabasi_albert_\"+str(i)] = [300]\n",
    "    elif topology_set ==\"big\":\n",
    "        for i in range(2):\n",
    "            each_network_topology_file[\"random_erdos_renyi_\"+str(i)]= \"data/size_\"+str(400)+\"_random_erdos_reni_0_0_1_\"+str(i)+\".txt\"\n",
    "    elif topology_set ==\"all\":\n",
    "        each_network_topology_file = {\"SURFnet\":'data/Surfnet',\"IBM\":'data/IBM',\"ATT\":'data/ATT_topology_file',\"Abilene\":'data/abilene'}\n",
    "        each_network_topology_file = {\"SURFnet\":'data/Surfnet'}\n",
    "        each_topology_mean_value_spike={\"ATT\":[250],\"IBM\":[250],\"SURFnet\":[250,200],\"Abilene\":[200,250]}\n",
    "        for i in [2]:\n",
    "            each_network_topology_file[\"G_50_0.05_\"+str(i)]= \"data/random_erdos_renyi2_\"+str(i)+\".txt\"\n",
    "            each_topology_mean_value_spike[\"G_50_0.05_\"+str(i)] = [350]\n",
    "            each_network_topology_file[\"PA_50_2_\"+str(i)]= \"data/random_barabasi_albert2_\"+str(i)+\".txt\"\n",
    "            each_topology_mean_value_spike[\"PA_50_2_\"+str(i)] = [350]\n",
    "        for i in [2]:\n",
    "            each_network_topology_file[\"PA_50_3_\"+str(i)]= \"data/random_barabasi_albert_\"+str(i)+\".txt\"\n",
    "            each_topology_mean_value_spike[\"PA_50_3_\"+str(i)] = [350]\n",
    "            each_network_topology_file[\"G_50_0.1_\"+str(i)]= \"data/random_erdos_renyi_\"+str(i)+\".txt\"\n",
    "            \n",
    "            each_topology_mean_value_spike[\"G_50_0.1_\"+str(i)] = [350]\n",
    "            \n",
    "            \n",
    "            \n",
    "    elif topology_set ==\"random_reny\":\n",
    "        for i in [2]:\n",
    "            each_network_topology_file[\"G_50_0.05_\"+str(i)]= \"data/random_erdos_renyi2_\"+str(i)+\".txt\"\n",
    "            each_network_topology_file[\"PA_50_3_\"+str(i)]= \"data/random_erdos_renyi_\"+str(i)+\".txt\"\n",
    "            each_topology_mean_value_spike[\"G_50_0.05_\"+str(i)] = [350,400]\n",
    "            each_topology_mean_value_spike[\"PA_50_3_\"+str(i)] = [350,400]\n",
    "\n",
    "    elif topology_set ==\"random\":\n",
    "        for i in [2]:\n",
    "            each_network_topology_file[\"random_barabasi_albert2_\"+str(i)]= \"data/random_barabasi_albert2_\"+str(i)+\".txt\"\n",
    "            each_network_topology_file[\"random_barabasi_albert_\"+str(i)]= \"data/random_barabasi_albert_\"+str(i)+\".txt\"\n",
    "            each_topology_mean_value_spike[\"random_barabasi_albert2_\"+str(i)] = [350,400]\n",
    "            each_topology_mean_value_spike[\"random_barabasi_albert_\"+str(i)] = [350,400]\n",
    "\n",
    "#         for i in range(1,2):\n",
    "#             each_network_topology_file[\"random_erdos_renyi_\"+str(i)]= \"data/random_erdos_renyi_\"+str(i)+\".txt\"\n",
    "#             each_network_topology_file[\"random_barabasi_albert_\"+str(i)]= \"data/random_barabasi_albert_\"+str(i)+\".txt\"\n",
    "#             each_topology_mean_value_spike[\"random_erdos_renyi_\"+str(i)] = [30]\n",
    "#             each_topology_mean_value_spike[\"random_barabasi_albert_\"+str(i)] = [30]\n",
    "    # import networkx as nx\n",
    "    # all_diameters = []\n",
    "    # for topology,file in each_network_topology_file.items():\n",
    "    #     print(\"for topology\",topology)\n",
    "\n",
    "    #     g = nx.Graph()\n",
    "    #     f = open(file, 'r')\n",
    "    #     header = f.readline()\n",
    "    #     for line in f:\n",
    "    #         line = line.strip()\n",
    "    #         link = line.split('\\t')\n",
    "    #         i, s, d, c = link\n",
    "    #         g.add_edge(int(s),int(d),weight=1)\n",
    "    #     f.close()  \n",
    "    #     all_diameters.append(nx.diameter(g))\n",
    "\n",
    "    feasibility(each_network_topology_file,results_file_path,inventory_utilization_results_file_path,delived_purification_EPRs_file_path,number_of_user_pairs,number_of_time_slots,spike_means,num_spikes,experiment_repeat,storage_node_selection_schemes,fidelity_threshold_ranges,cyclic_workload,storage_capacities,given_life_time_set,distance_between_users,setting_demands,edge_fidelity_ranges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "\"\"\"We have 6 pairs of users\"\"\"\n",
    "each_topology_mean_value_spike={\"ATT\":200,\"IBM\":0,\"SURFnet\":200,\"Abilene\":150\n",
    "                               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
